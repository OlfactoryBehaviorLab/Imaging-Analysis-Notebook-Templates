{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dewan Lab EPM Analysis\n",
    "## 0: Run once to create all needed directories at beginning of a project"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1471a0c2b0c3e8ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dewan_calcium.helpers import DewanIOhandler\n",
    "DewanIOhandler.create_project_framework('EPM')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:54:46.580267Z",
     "start_time": "2024-04-21T22:54:46.506269Z"
    }
   },
   "id": "39f6dabec1868cdf",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5d20e6bdd90448"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea0c658343a138ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from dewan_calcium import DewanDeconv\n",
    "from dewan_calcium.helpers import DewanEPM, DewanIOhandler, DewanJSON"
   ],
   "metadata": {
    "collapsed": true
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1B: User Configurables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbadb82b6bdf09c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "# TODO: Get these configurables from the JSON file using the JSON Module\n",
    "\n",
    "# Settings from Inscopix box\n",
    "LED_power = 1\n",
    "GAIN = 2.2\n",
    "FOCUS = 250\n",
    "\n",
    "fileHeader = animal + '-' + date + '-'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17c61cc38601c39"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_path = Path('Z:\\\\2_Inscopix\\\\1_DTT\\\\3_EPM\\VGLUT-20')\n",
    "\n",
    "DewanIOhandler.create_project_framework('EPM', test_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b153d57361969394",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2A: Import and pre-process the raw data\n",
    "\n",
    "#### Copy DLC output .h5 file and labled video -> EPM_Analysis\\RawData"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e0375d9126c67a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# New way that we should be grabbing the data\n",
    "\n",
    "#STEP 2A.1: LOAD DLC DATA\n",
    "# Read in data for processing.  Needs Cell Traces, Odor List, and GPIO file.\n",
    "dlc_path_stem = Path(*['EPM_Analysis','DLC_Data'])\n",
    "dlc_path = test_path.joinpath(dlc_path_stem)\n",
    "\n",
    "labeled_video_path = list(dlc_path.glob('DLC*labeled*')) # Usually mp4 files, but this is more flexible\n",
    "points_path = list(dlc_path.glob('*.h5'))\n",
    "\n",
    "tracked_points = pd.read_hdf(points_path)  # Load tracked points\n",
    "labeled_video = cv2.VideoCapture(str(labeled_video_path))  # Load Video"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9b3d146c77c791e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#STEP 2A.2: LOAD INSCOPIX DATA\n",
    "\n",
    "inscopix_path_stem = Path(*['InscopixProcessing', 'DataAnalysis'])  # Rename this to inscopix_path when done testing and delete the line below\n",
    "inscopix_path = test_path.joinpath(inscopix_path_stem)\n",
    "\n",
    "# We assume there is only one file that matches each query\n",
    "cell_trace_path = list(inscopix_path.glob('*TRACES.csv'))[0]\n",
    "GPIO_path = list(inscopix_path.glob('*GPIO.csv'))[0]\n",
    "cell_props_path = list(inscopix_path.glob('*props.csv'))[0]\n",
    "contours_path = list(inscopix_path.glob('*CONTOURS.json'))[0]\n",
    "max_projection_path = list(inscopix_path.glob('*HD*MAX_PROJ.tiff'))[0]  # Match anything that includes HD and MAX_PROJ"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48a218843c969238",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cell_trace_data = pd.read_csv(cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(GPIO_path, header=None, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(cell_props_path, header=0, engine='pyarrow')\n",
    "cell_keys, cell_outlines = DewanJSON.get_outline_coordinates(contours_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abd14e642db457ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2A.2: PREPROCESSING\n",
    "\n",
    "# STEP 2A.2.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data.drop([0], inplace=True)\n",
    "\n",
    "# STEP 2A.2.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data.set_index(cell_trace_data.columns[0], inplace=True)\n",
    "\n",
    "# STEP 2A.2.3: Remove spaces from column names\n",
    "cell_trace_data.columns = [key.replace(' ', '') for key in cell_trace_data.columns.values]\n",
    "\n",
    "# STEP 2A.2.4: REMOVE ALL MULTI-COMPONENT CELLS\n",
    "# Generate a list of cell numbers based off the number of cells\n",
    "cell_list = np.arange(len(all_cell_props['NumComponents'])) # Example Cell Numbers: 0, 1, 2, 3, 4\n",
    "# Get indices where there are only one cell part\n",
    "one_piece_cells = np.where(all_cell_props['NumComponents'] == 1)[0] # Example One-Component Indexes: 0, 1, 4\n",
    "# Filter out all the multi-component cells, leaving only the one-piece cells\n",
    "cell_list = cell_list[one_piece_cells] # Example Filtered Cell Numbers: 0, 1 ,4\n",
    "cell_keys = cell_keys[one_piece_cells] # Example Filtered Cell Keys, C00, C01, C04\n",
    "all_cell_props = all_cell_props.iloc[one_piece_cells] # Filter out two-piece cells as above\n",
    "\n",
    "# STEP 2A.2.5: PARSE GPIO DATA\n",
    "GPIO_data.iloc[:, 1] = GPIO_data.iloc[:, 1].str.replace(' ', '')  # Remove Random Spaces in Data\n",
    "GPIO1 = np.array(GPIO_data.iloc[:, 1] == \"GPIO-1\")  # Get Sniff Sensor Data Truth Table\n",
    "GPIO2 = np.array(GPIO_data.iloc[:, 1] == \"GPIO-2\")  # Get FV Actuation Data Truth Table\n",
    "FV_data = np.array(GPIO_data.iloc[GPIO2,:]) # Create an array with FV values only\n",
    "\n",
    "# STEP 2A.2.6: Make all numeric values floats and remove nullbytes\n",
    "\n",
    "remove_null_bytes = lambda item: item.split('\\x00')[0]\n",
    "# For some reason the data will occasionally contain a very long string of null bytes '\\\\x00'\n",
    "# this will remove everything after the null bytes,\n",
    "\n",
    "# Iterate over each item and remove the nullbytes; simultaneously cast values to floats\n",
    "FV_data[:, 0] = np.fromiter(map(remove_null_bytes, FV_data[:, 0]), 'float')\n",
    "FV_data[:, 2] = np.fromiter(map(remove_null_bytes, FV_data[:, 2]), 'float')\n",
    "\n",
    "cols = ['mouse_x', 'mouse_y', 'mouse_p', 'led_x', 'led_y', 'led_p'] \n",
    "# Reset the column names to something sensible\n",
    "tracked_points.columns = cols "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f314d311576ad6e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# There may be an instance where the model erroneously identified the LED for very short time periods\n",
    "# find_led_start bins the possible LED on times (anywhere led_p > 0.98)\n",
    "# We then find the bin with the largest size, which means it has the most frames where the LED is identified\n",
    "# This is most likely the period where the experimenter turned on the LED\n",
    "led_bins = np.array(DewanEPM.find_led_start(tracked_points))\n",
    "true_led_bin = np.argmax(np.subtract(led_bins[:, 1], led_bins[:,0]))\n",
    "\n",
    "led_on = led_bins[true_led_bin][0] # Find first row where the LED is 'on'\n",
    "good_points = tracked_points.iloc[led_on:-1] # Delete all data before the LED is 'on'\n",
    "good_points.reset_index(drop=True, inplace=True) # Reset the index\n",
    "\n",
    "# Get X, Y coordinates, cast to int, and combine them into tuples\n",
    "head_x = good_points['mouse_x'].astype(int)\n",
    "head_y = good_points['mouse_y'].astype(int)\n",
    "coordinates = list(zip(head_x, head_y))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c77b4569ed5cad3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "_ = labeled_video.set(cv2.CAP_PROP_POS_FRAMES, led_on)  # Set the first frame to the first LED frame\n",
    "_, frame = labeled_video.read() # Read said frame\n",
    "\n",
    "for pair in coordinates:  # Loop through each coordinate and draw a red point\n",
    "    cv2.circle(frame, pair, 0, (0,0,255), -1)\n",
    "\n",
    "# _ = cv2.imwrite(str(image_path), frame) # Save image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4a2d5bb9e31ac7d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
