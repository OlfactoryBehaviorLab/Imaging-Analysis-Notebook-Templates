{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dewan Lab EPM Analysis\n",
    "## 0: Run once to create all needed directories at beginning of a project"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1471a0c2b0c3e8ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dewan_calcium.helpers import DewanIOhandler\n",
    "DewanIOhandler.create_project_framework('EPM')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T22:54:46.580267Z",
     "start_time": "2024-04-21T22:54:46.506269Z"
    }
   },
   "id": "39f6dabec1868cdf",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5d20e6bdd90448"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea0c658343a138ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from dewan_calcium import DewanDeconv, DewanManualCuration\n",
    "from dewan_calcium.helpers import DewanEPM, DewanIOhandler, DewanJSON"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:17:59.799465600Z",
     "start_time": "2024-04-22T23:17:57.008100Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1B: User Configurables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbadb82b6bdf09c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "# TODO: Get these configurables from the JSON file using the JSON Module\n",
    "\n",
    "# Settings from Inscopix box\n",
    "LED_power = 1\n",
    "GAIN = 2.2\n",
    "FOCUS = 250\n",
    "\n",
    "EXPERIMENT_TIME = 10  # Time in minutes for the experiment\n",
    "\n",
    "fileHeader = animal + '-' + date + '-'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:22:49.825194900Z",
     "start_time": "2024-04-22T23:22:49.737722700Z"
    }
   },
   "id": "d17c61cc38601c39",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_path = Path('R:\\\\2_Inscopix\\\\1_DTT\\\\3_EPM\\VGLUT-20')\n",
    "\n",
    "DewanIOhandler.create_project_framework('EPM', test_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:18:00.003557100Z",
     "start_time": "2024-04-22T23:17:59.904929600Z"
    }
   },
   "id": "b153d57361969394",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2A: Import and pre-process the raw data\n",
    "\n",
    "#### Copy DLC output .h5 file and labled video -> EPM_Analysis\\RawData"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e0375d9126c67a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CAUTION WARNING HEY LOOK HERE WE ARE USING VGAT12 DLC DATA WITH VGLUT20 NEURAL DATA FOR TESTING PURPOSES\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2017b4d416b19f9c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# New way that we should be grabbing the data\n",
    "\n",
    "#STEP 2A.1: LOAD DLC DATA\n",
    "# Read in data for processing.  Needs Cell Traces, Odor List, and GPIO file.\n",
    "dlc_path_stem = Path(*['EPM_Analysis','DLC_Data'])\n",
    "dlc_path = test_path.joinpath(dlc_path_stem)\n",
    "\n",
    "labeled_video_path = list(dlc_path.glob('*DLC*labeled*'))[0] # Usually mp4 files, but this is more flexible\n",
    "points_path = list(dlc_path.glob('*.h5'))[0]\n",
    "\n",
    "tracked_points = pd.read_hdf(points_path)  # Load tracked points\n",
    "labeled_video = cv2.VideoCapture(str(labeled_video_path))  # Load Video\n",
    "\n",
    "VIDEO_FPS = labeled_video.get(cv2.CAP_PROP_FPS)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:19:49.547516600Z",
     "start_time": "2024-04-22T23:19:49.390297400Z"
    }
   },
   "id": "a9b3d146c77c791e",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#STEP 2A.2: LOAD INSCOPIX DATA\n",
    "\n",
    "inscopix_path_stem = Path(*['InscopixProcessing', 'DataAnalysis'])  # Rename this to inscopix_path when done testing and delete the line below\n",
    "inscopix_path = test_path.joinpath(inscopix_path_stem)\n",
    "\n",
    "# We assume there is only one file that matches each query\n",
    "cell_trace_path = list(inscopix_path.glob('*TRACES.csv'))[0]\n",
    "GPIO_path = list(inscopix_path.glob('*GPIO.csv'))[0]\n",
    "cell_props_path = list(inscopix_path.glob('*props.csv'))[0]\n",
    "contours_path = list(inscopix_path.glob('*CONTOURS.json'))[0]\n",
    "max_projection_path = list(inscopix_path.glob('*HD*MAX_PROJ.tiff'))[0]  # Match anything that includes HD and MAX_PROJ\n",
    "\n",
    "cell_trace_data = pd.read_csv(cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(GPIO_path, header=None, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(cell_props_path, header=0, engine='pyarrow')\n",
    "cell_keys, cell_outlines = DewanJSON.get_outline_coordinates(contours_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:49:00.185736700Z",
     "start_time": "2024-04-22T22:48:59.291221500Z"
    }
   },
   "id": "abd14e642db457ce",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2A.2: PREPROCESSING\n",
    "\n",
    "# STEP 2A.2.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data.drop([0], inplace=True)\n",
    "\n",
    "# STEP 2A.2.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data.set_index(cell_trace_data.columns[0], inplace=True)\n",
    "\n",
    "# STEP 2A.2.3: Remove spaces from column names\n",
    "cell_trace_data.columns = [key.replace(' ', '') for key in cell_trace_data.columns.values]\n",
    "\n",
    "# STEP 2A.2.4: REMOVE ALL MULTI-COMPONENT CELLS\n",
    "# Generate a list of cell numbers based off the number of cells\n",
    "cell_list = np.arange(len(all_cell_props['NumComponents'])) # Example Cell Numbers: 0, 1, 2, 3, 4\n",
    "# Get indices where there are only one cell part\n",
    "one_piece_cells = np.where(all_cell_props['NumComponents'] == 1)[0] # Example One-Component Indexes: 0, 1, 4\n",
    "# Filter out all the multi-component cells, leaving only the one-piece cells\n",
    "cell_list = cell_list[one_piece_cells] # Example Filtered Cell Numbers: 0, 1 ,4\n",
    "cell_keys = cell_keys[one_piece_cells] # Example Filtered Cell Keys, C00, C01, C04\n",
    "all_cell_props = all_cell_props.iloc[one_piece_cells] # Filter out two-piece cells as above\n",
    "\n",
    "# STEP 2A.2.5: PARSE GPIO DATA\n",
    "GPIO_data.iloc[:, 1] = GPIO_data.iloc[:, 1].str.replace(' ', '')  # Remove Random Spaces in Data\n",
    "GPIO1 = np.array(GPIO_data.iloc[:, 1] == \"GPIO-1\")  # Get Sniff Sensor Data Truth Table\n",
    "GPIO2 = np.array(GPIO_data.iloc[:, 1] == \"GPIO-2\")  # Get FV Actuation Data Truth Table\n",
    "FV_data = np.array(GPIO_data.iloc[GPIO2,:]) # Create an array with FV values only\n",
    "\n",
    "# STEP 2A.2.6: Make all numeric values floats and remove nullbytes\n",
    "\n",
    "remove_null_bytes = lambda item: item.split('\\x00')[0]\n",
    "# For some reason the data will occasionally contain a very long string of null bytes '\\\\x00'\n",
    "# this will remove everything after the null bytes,\n",
    "\n",
    "# Iterate over each item and remove the nullbytes; simultaneously cast values to floats\n",
    "FV_data[:, 0] = np.fromiter(map(remove_null_bytes, FV_data[:, 0]), 'float')\n",
    "FV_data[:, 2] = np.fromiter(map(remove_null_bytes, FV_data[:, 2]), 'float')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c367711c48588a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2A.3: PREPROCESSING DLC Data\n",
    "\n",
    "cols = ['mouse_x', 'mouse_y', 'mouse_p', 'led_x', 'led_y', 'led_p'] \n",
    "# Reset the column names to something sensible\n",
    "tracked_points.columns = cols "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:09:58.518349600Z",
     "start_time": "2024-04-22T23:09:58.435754300Z"
    }
   },
   "id": "6f314d311576ad6e",
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2B: Manual Curation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e21d1f96278b274b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2B.1: Load the Maximum Projection Image, draw the cell outlines and labels, and output labeled image\n",
    "MaxProjectionImage = DewanManualCuration.generate_max_projection(max_projection_path, all_cell_props, cell_keys, cell_outlines, return_raw_image=False)\n",
    "# generate_max_projection(ImagePath, AllCellProps, CellKeys, CellOutlines, return_raw_iamge, is_downsampled=False, downsample_factor=4, brightness=1.5, contrast=1.5, font_size=24, text_color='red', outline_color='yellow', outline_width=2):\n",
    "# Optional configuration values that are set by default, change as desired\n",
    "# Note: Set save_image=True to output a max projection with all cells detected by CNMFE regardless if they are good cells or not\n",
    "\n",
    "# STEP 2B.2: Run ManualCuration GUI\n",
    "good_cells = DewanManualCuration.manual_curation_gui(cell_list, cell_trace_data, MaxProjectionImage)\n",
    "if good_cells is None:\n",
    "    print('Error, no good cells selected!')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:53:38.657311500Z",
     "start_time": "2024-04-22T22:52:30.696586200Z"
    }
   },
   "id": "e6d6c2c8fc4f07b6",
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2C: Apply Manual Curation Results and Additional Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba514ce06958860"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2C.1: Filter all data by the GoodCells identified in ManualCuration\n",
    "good_cell_props = all_cell_props.iloc[good_cells, :]\n",
    "good_cell_props.reset_index()  # Resets index to 0 -> len(GoodCellProperties)\n",
    "good_cell_list = cell_list[good_cells]\n",
    "good_cell_keys = cell_keys[good_cells]\n",
    "good_cell_trace_data = cell_trace_data.iloc[:, good_cells]\n",
    "\n",
    "\n",
    "# STEP 2C.2: OUTPUT MAX PROJECTION IMAGE WITH CONTOURS OF GOOD CELLS\n",
    "image = DewanManualCuration.generate_max_projection(max_projection_path, good_cell_props, good_cell_keys, cell_outlines,\n",
    "                                                    return_raw_image=True)\n",
    "# generate_max_projection(ImagePath, AllCellProps, CellKeys, CellOutlines, return_raw_image, brightness=1.5, contrast=1.5, font_size=24, text_color='red', outline_color='yellow', outline_width=2):\n",
    "# Optional configuration values that are set by default, change as desired\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T22:55:33.716570Z",
     "start_time": "2024-04-22T22:55:33.259560Z"
    }
   },
   "id": "6d4ee4dc735b1d81",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2D: Pickle and Save all preprocessed data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bec801c85b27c1bb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-good_cell_trace_data has been saved!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-GPIO_data has been saved!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-FV_data has been saved!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-good_cell_props has been saved!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-good_cell_list has been saved!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-tracked_points has been saved!\n"
     ]
    }
   ],
   "source": [
    "# Pickle the reorganized CellTraceData incase its needed later\n",
    "# Saves Cell Traces, GPIO, Odor List, Sniff, FV data, Good Cell Properties, Good Cells, and the labeled max projection\n",
    "# Once these have been saved, they don't need to be re-run on the same data again unless the data itself is changed\n",
    "\n",
    "folder_stem = ['EPM_Analysis', 'PreProcessedData']\n",
    "folder = test_path.joinpath(*folder_stem)\n",
    "folder = folder.parts\n",
    "\n",
    "DewanManualCuration.save_image(image, folder)\n",
    "DewanIOhandler.save_data_to_disk(good_cell_trace_data, 'good_cell_trace_data', fileHeader, folder, True)\n",
    "DewanIOhandler.save_data_to_disk(GPIO_data, 'GPIO_data', fileHeader, folder, True)\n",
    "DewanIOhandler.save_data_to_disk(FV_data, 'FV_data', fileHeader, folder, False)\n",
    "DewanIOhandler.save_data_to_disk(good_cell_props, 'good_cell_props', fileHeader, folder, True)\n",
    "DewanIOhandler.save_data_to_disk(good_cell_list, 'good_cell_list', fileHeader, folder, False)\n",
    "\n",
    "DewanIOhandler.save_data_to_disk(tracked_points, 'tracked_points', fileHeader, folder, True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:10:06.111657100Z",
     "start_time": "2024-04-22T23:10:03.769129400Z"
    }
   },
   "id": "176c5be1ba73ca5e",
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-good_cell_trace_data has loaded successfully!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-GPIO_data has loaded successfully!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-FV_data has loaded successfully!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-good_cell_props has loaded successfully!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-good_cell_list has loaded successfully!\n",
      "ANIMAL_GOES_HERE-DATE_GOES_HERE-tracked_points has loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Opens the saved pickle files.  If the files have already been saved, code can be re-run\n",
    "# starting from this point\n",
    "\n",
    "folder_stem = ['EPM_Analysis', 'PreProcessedData']\n",
    "folder = test_path.joinpath(*folder_stem)\n",
    "folder = folder.parts\n",
    "\n",
    "good_cell_trace_data = DewanIOhandler.load_data_from_disk('good_cell_trace_data', fileHeader, folder, True)\n",
    "GPIO_data = DewanIOhandler.load_data_from_disk('GPIO_data', fileHeader, folder, True)\n",
    "FV_data = DewanIOhandler.load_data_from_disk('FV_data', fileHeader, folder, False)\n",
    "good_cell_props = DewanIOhandler.load_data_from_disk('good_cell_props', fileHeader, folder, True)\n",
    "good_cell_list = DewanIOhandler.load_data_from_disk('good_cell_list', fileHeader, folder, False)\n",
    "tracked_points = DewanIOhandler.load_data_from_disk('tracked_points', fileHeader, folder, False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-22T23:24:13.609612500Z",
     "start_time": "2024-04-22T23:24:12.912767800Z"
    }
   },
   "id": "6c706c8b64d42488",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# There may be an instance where the model erroneously identified the LED for very short time periods\n",
    "# find_led_start bins the possible LED on times (anywhere led_p > 0.98)\n",
    "# We then find the bin with the largest size, which means it has the most frames where the LED is identified\n",
    "# This is most likely the period where the experimenter turned on the LED\n",
    "led_bins = np.array(DewanEPM.find_led_start(tracked_points))\n",
    "true_led_bin = np.argmax(np.subtract(led_bins[:, 1], led_bins[:,0]))\n",
    "\n",
    "led_on = led_bins[true_led_bin][0] # Find first row where the LED is 'on'\n",
    "good_points = tracked_points.iloc[led_on:-1] # Delete all data before the LED is 'on'\n",
    "good_points.reset_index(drop=True, inplace=True) # Reset the index\n",
    "\n",
    "# Get X, Y coordinates, cast to int, and combine them into tuples\n",
    "head_x = good_points['mouse_x'].astype(int)\n",
    "head_y = good_points['mouse_y'].astype(int)\n",
    "coordinates = list(zip(head_x, head_y))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c77b4569ed5cad3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "_ = labeled_video.set(cv2.CAP_PROP_POS_FRAMES, led_on)  # Set the first frame to the first LED frame\n",
    "_, frame = labeled_video.read() # Read said frame\n",
    "\n",
    "for pair in coordinates:  # Loop through each coordinate and draw a red point\n",
    "    cv2.circle(frame, pair, 0, (0,0,255), -1)\n",
    "\n",
    "# _ = cv2.imwrite(str(image_path), frame) # Save image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4a2d5bb9e31ac7d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
