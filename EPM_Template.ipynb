{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dewan Lab EPM Analysis\n",
    "## 0: Run once to create all needed directories at beginning of a project"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1471a0c2b0c3e8ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from dewan_calcium.helpers import DewanIOhandler\n",
    "DewanIOhandler.create_project_framework('EPM')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39f6dabec1868cdf",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5d20e6bdd90448"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea0c658343a138ee",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "from roipoly import MultiRoi  ## Must be installed from Github as the PyPi version is obsolete; pip install git+https://github.com/jdoepfert/roipoly.py\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from dewan_calcium import DewanDeconv, DewanManualCuration\n",
    "from dewan_calcium.helpers import DewanEPM, DewanIOhandler, DewanJSON"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1B: User Configurables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbadb82b6bdf09c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "# TODO: Get these configurables from the JSON file using the JSON Module\n",
    "\n",
    "# Settings from Inscopix box\n",
    "LED_power = 1\n",
    "GAIN = 2.2\n",
    "FOCUS = 250\n",
    "\n",
    "EXPERIMENT_TIME = 15  # Time in minutes for the experiment\n",
    "\n",
    "fileHeader = animal + '-' + date + '-'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17c61cc38601c39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_path = Path('R:\\\\2_Inscopix\\\\1_DTT\\\\3_EPM\\VGLUT-20')\n",
    "\n",
    "DewanIOhandler.create_project_framework('EPM', test_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b153d57361969394",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2A: Import and pre-process the raw data\n",
    "\n",
    "#### Copy DLC output .h5 file and labled video -> EPM_Analysis\\RawData"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8e0375d9126c67a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# New way that we should be grabbing the data\n",
    "\n",
    "#STEP 2A.1: LOAD DLC DATA\n",
    "# Read in data for processing.  Needs Cell Traces, Odor List, and GPIO file.\n",
    "dlc_path_stem = Path(*['EPM_Analysis','DLC_Data'])\n",
    "dlc_path = test_path.joinpath(dlc_path_stem)\n",
    "\n",
    "labeled_video_path = list(dlc_path.glob('*DLC*labeled*'))[0] # Usually mp4 files, but this is more flexible\n",
    "points_path = list(dlc_path.glob('*.h5'))[0]\n",
    "\n",
    "tracked_points = pd.read_hdf(points_path)  # Load tracked points"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "657f2ba38c25a353",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "labeled_video = cv2.VideoCapture(str(labeled_video_path))  # Load Video\n",
    "\n",
    "VIDEO_FPS = labeled_video.get(cv2.CAP_PROP_FPS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9b3d146c77c791e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#STEP 2A.2: LOAD INSCOPIX DATA\n",
    "\n",
    "inscopix_path_stem = Path(*['InscopixProcessing', 'DataAnalysis'])  # Rename this to inscopix_path when done testing and delete the line below\n",
    "inscopix_path = test_path.joinpath(inscopix_path_stem)\n",
    "\n",
    "# We assume there is only one file that matches each query\n",
    "cell_trace_path = list(inscopix_path.glob('*TRACES.csv'))[0]\n",
    "GPIO_path = list(inscopix_path.glob('*GPIO.csv'))[0]\n",
    "cell_props_path = list(inscopix_path.glob('*props.csv'))[0]\n",
    "contours_path = list(inscopix_path.glob('*CONTOURS.json'))[0]\n",
    "max_projection_path = list(inscopix_path.glob('*HD*MAX_PROJ.tiff'))[0]  # Match anything that includes HD and MAX_PROJ\n",
    "\n",
    "cell_trace_data = pd.read_csv(cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(GPIO_path, header=None, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(cell_props_path, header=0, engine='pyarrow')\n",
    "cell_keys, cell_outlines = DewanJSON.get_outline_coordinates(contours_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abd14e642db457ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2A.2: PREPROCESSING\n",
    "\n",
    "# STEP 2A.2.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data.drop([0], inplace=True)\n",
    "\n",
    "# STEP 2A.2.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data.set_index(cell_trace_data.columns[0], inplace=True)\n",
    "\n",
    "# STEP 2A.2.3: Remove spaces from column names\n",
    "cell_trace_data.columns = [key.replace(' ', '') for key in cell_trace_data.columns.values]\n",
    "\n",
    "# STEP 2A.2.4: REMOVE ALL MULTI-COMPONENT CELLS\n",
    "# Generate a list of cell numbers based off the number of cells\n",
    "cell_list = np.arange(len(all_cell_props['NumComponents'])) # Example Cell Numbers: 0, 1, 2, 3, 4\n",
    "# Get indices where there are only one cell part\n",
    "one_piece_cells = np.where(all_cell_props['NumComponents'] == 1)[0] # Example One-Component Indexes: 0, 1, 4\n",
    "# Filter out all the multi-component cells, leaving only the one-piece cells\n",
    "cell_list = cell_list[one_piece_cells] # Example Filtered Cell Numbers: 0, 1 ,4\n",
    "cell_keys = cell_keys[one_piece_cells] # Example Filtered Cell Keys, C00, C01, C04\n",
    "all_cell_props = all_cell_props.iloc[one_piece_cells] # Filter out two-piece cells as above\n",
    "\n",
    "# STEP 2A.2.5: PARSE GPIO DATA\n",
    "GPIO_data.iloc[:, 1] = GPIO_data.iloc[:, 1].str.replace(' ', '')  # Remove Random Spaces in Data\n",
    "GPIO1 = np.array(GPIO_data.iloc[:, 1] == \"GPIO-1\")  # Get Sniff Sensor Data Truth Table\n",
    "GPIO2 = np.array(GPIO_data.iloc[:, 1] == \"GPIO-2\")  # Get FV Actuation Data Truth Table\n",
    "FV_data = np.array(GPIO_data.iloc[GPIO2,:]) # Create an array with FV values only\n",
    "\n",
    "# STEP 2A.2.6: Make all numeric values floats and remove nullbytes\n",
    "\n",
    "remove_null_bytes = lambda item: item.split('\\x00')[0]\n",
    "# For some reason the data will occasionally contain a very long string of null bytes '\\\\x00'\n",
    "# this will remove everything after the null bytes,\n",
    "\n",
    "# Iterate over each item and remove the nullbytes; simultaneously cast values to floats\n",
    "FV_data[:, 0] = np.fromiter(map(remove_null_bytes, FV_data[:, 0]), 'float')\n",
    "FV_data[:, 2] = np.fromiter(map(remove_null_bytes, FV_data[:, 2]), 'float')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c367711c48588a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2A.3: PREPROCESSING DLC Data\n",
    "\n",
    "cols = ['mouse_x', 'mouse_y', 'mouse_p', 'led_x', 'led_y', 'led_p'] \n",
    "# Reset the column names to something sensible\n",
    "tracked_points.columns = cols "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f314d311576ad6e",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2B: Manual Curation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e21d1f96278b274b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2B.1: Load the Maximum Projection Image, draw the cell outlines and labels, and output labeled image\n",
    "MaxProjectionImage = DewanManualCuration.generate_max_projection(max_projection_path, all_cell_props, cell_keys, cell_outlines, return_raw_image=False)\n",
    "# generate_max_projection(ImagePath, AllCellProps, CellKeys, CellOutlines, return_raw_iamge, is_downsampled=False, downsample_factor=4, brightness=1.5, contrast=1.5, font_size=24, text_color='red', outline_color='yellow', outline_width=2):\n",
    "# Optional configuration values that are set by default, change as desired\n",
    "# Note: Set save_image=True to output a max projection with all cells detected by CNMFE regardless if they are good cells or not\n",
    "\n",
    "# STEP 2B.2: Run ManualCuration GUI\n",
    "good_cells = DewanManualCuration.manual_curation_gui(cell_list, cell_trace_data, MaxProjectionImage)\n",
    "if good_cells is None:\n",
    "    print('Error, no good cells selected!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d6c2c8fc4f07b6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2C: Apply Manual Curation Results and Additional Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba514ce06958860"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2C.1: Filter all data by the GoodCells identified in ManualCuration\n",
    "good_cell_props = all_cell_props.iloc[good_cells, :]\n",
    "good_cell_props.reset_index()  # Resets index to 0 -> len(GoodCellProperties)\n",
    "good_cell_list = cell_list[good_cells]\n",
    "good_cell_keys = cell_keys[good_cells]\n",
    "good_cell_trace_data = cell_trace_data.iloc[:, good_cells]\n",
    "\n",
    "\n",
    "# STEP 2C.2: OUTPUT MAX PROJECTION IMAGE WITH CONTOURS OF GOOD CELLS\n",
    "image = DewanManualCuration.generate_max_projection(max_projection_path, good_cell_props, good_cell_keys, cell_outlines,\n",
    "                                                    return_raw_image=True)\n",
    "# generate_max_projection(ImagePath, AllCellProps, CellKeys, CellOutlines, return_raw_image, brightness=1.5, contrast=1.5, font_size=24, text_color='red', outline_color='yellow', outline_width=2):\n",
    "# Optional configuration values that are set by default, change as desired\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d4ee4dc735b1d81",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2D: Pickle and Save all preprocessed data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bec801c85b27c1bb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Pickle the reorganized CellTraceData incase its needed later\n",
    "# Saves Cell Traces, GPIO, Odor List, Sniff, FV data, Good Cell Properties, Good Cells, and the labeled max projection\n",
    "# Once these have been saved, they don't need to be re-run on the same data again unless the data itself is changed\n",
    "\n",
    "folder_stem = ['EPM_Analysis', 'PreProcessedData']\n",
    "folder = test_path.joinpath(*folder_stem)\n",
    "folder = folder.parts\n",
    "\n",
    "DewanManualCuration.save_image(image, folder)\n",
    "DewanIOhandler.save_data_to_disk(good_cell_trace_data, 'good_cell_trace_data', fileHeader, folder, True)\n",
    "DewanIOhandler.save_data_to_disk(GPIO_data, 'GPIO_data', fileHeader, folder, True)\n",
    "DewanIOhandler.save_data_to_disk(FV_data, 'FV_data', fileHeader, folder, False)\n",
    "DewanIOhandler.save_data_to_disk(good_cell_props, 'good_cell_props', fileHeader, folder, True)\n",
    "DewanIOhandler.save_data_to_disk(good_cell_list, 'good_cell_list', fileHeader, folder, False)\n",
    "\n",
    "DewanIOhandler.save_data_to_disk(tracked_points, 'tracked_points', fileHeader, folder, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "176c5be1ba73ca5e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Opens the saved pickle files.  If the files have already been saved, code can be re-run\n",
    "# starting from this point\n",
    "\n",
    "folder_stem = ['EPM_Analysis', 'PreProcessedData']\n",
    "folder = test_path.joinpath(*folder_stem)\n",
    "folder = folder.parts\n",
    "\n",
    "good_cell_trace_data = DewanIOhandler.load_data_from_disk('good_cell_trace_data', fileHeader, folder, True)\n",
    "GPIO_data = DewanIOhandler.load_data_from_disk('GPIO_data', fileHeader, folder, True)\n",
    "FV_data = DewanIOhandler.load_data_from_disk('FV_data', fileHeader, folder, False)\n",
    "good_cell_props = DewanIOhandler.load_data_from_disk('good_cell_props', fileHeader, folder, True)\n",
    "good_cell_list = DewanIOhandler.load_data_from_disk('good_cell_list', fileHeader, folder, False)\n",
    "\n",
    "tracked_points = DewanIOhandler.load_data_from_disk('tracked_points', fileHeader, folder, False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c706c8b64d42488",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# There may be an instance where the model erroneously identified the LED for very short time periods\n",
    "# find_led_start bins the possible LED on times (anywhere led_p > 0.98)\n",
    "# We then find the bin with the largest size, which means it has the most frames where the LED is identified\n",
    "# This is most likely the period where the experimenter turned on the LED\n",
    "led_bins = np.array(DewanEPM.find_led_start(tracked_points))\n",
    "\n",
    "true_led_bin = np.argmax(np.subtract(led_bins[:, 1], led_bins[:,0]))\n",
    "\n",
    "led_on = led_bins[true_led_bin][0] # Find first row where the LED is 'on'\n",
    "experiment_frames = int(VIDEO_FPS * 60 * EXPERIMENT_TIME)  # FPS * 60 s/min * experiment length in minutes --> number of frames\n",
    "end_frame = led_on + experiment_frames\n",
    "\n",
    "good_points = tracked_points.iloc[led_on:end_frame] # Subset the frames from LED_ON -> ten minutes later\n",
    "good_points.reset_index(drop=True, inplace=True) # Reset the index\n",
    "\n",
    "# Get X, Y coordinates, cast to int, and combine them into tuples\n",
    "head_x = good_points['mouse_x'].astype(int)\n",
    "head_y = good_points['mouse_y'].astype(int)\n",
    "coordinates = np.fromiter(zip(head_x, head_y), dtype=object)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c77b4569ed5cad3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 3A: Parses the final valve data to identify when the final valve is open vs when it is closed based on TTL pulse from Arduino.\n",
    "FV_values = FV_data[:, 2].astype(float) # Get FV Values\n",
    "num_values = len(FV_values)\n",
    "valve_status = 0\n",
    "FV_off_index = []\n",
    "FV_on_index = []\n",
    "for i in trange((num_values - 1), desc=\"Processing: \"):\n",
    "    valve_value_diff = FV_values[i + 1] - FV_values[i]\n",
    "\n",
    "    if valve_status == 0:    # Start with valve off\n",
    "        if valve_value_diff > 10000: # If the difference is a very large positive number, the valve opened\n",
    "            FV_on_index.append(i + 1)\n",
    "            valve_status = 1 # Set valve state to open\n",
    "    else:\n",
    "        if valve_value_diff < -10000: # If the difference is a very large negative number, the valve closed\n",
    "            FV_off_index.append(i)\n",
    "            valve_status = 0 # Set valve state to closed\n",
    "\n",
    "FV_off_index = np.array(FV_off_index)  # convert list to np array\n",
    "FV_on_index = np.array(FV_on_index)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5505d5ba98ede822",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "experiment_start_index = FV_on_index[0]\n",
    "trial_start_time = FV_data[experiment_start_index, 0]  # Trial start time in unix time (s)\n",
    "trial_end_time = trial_start_time + (EXPERIMENT_TIME * 60)  # End time is whatever the duration of the experiment was in minutes\n",
    "\n",
    "cell_trace_times = good_cell_trace_data.index.values\n",
    "\n",
    "cell_trace_on_index = np.where(cell_trace_times <= trial_start_time)[0][-1]\n",
    "cell_trace_off_index = np.where(cell_trace_times <= trial_end_time)[0][-1]  # We can't overshoot otherwise the coordinate will not match, so we may drop a single frame\n",
    "\n",
    "trimmed_good_cell_trace_data = good_cell_trace_data.iloc[cell_trace_on_index:cell_trace_off_index, :]\n",
    "\n",
    "trimmed_cell_trace_times = trimmed_good_cell_trace_data.index.values\n",
    "shifted_cell_trace_times = np.subtract(trimmed_cell_trace_times, trimmed_cell_trace_times[0])\n",
    "rounded_cell_trace_times = np.round(shifted_cell_trace_times, 1)\n",
    "\n",
    "trimmed_good_cell_trace_data.index = rounded_cell_trace_times\n",
    "\n",
    "good_points_index = good_points.index.values\n",
    "good_points_time = np.divide(good_points_index, VIDEO_FPS)\n",
    "good_points.index = good_points_time"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "60552b9f3540b418",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Align Cell Traces with the DLC Data\n",
    "## Since the DLC data is typically recorded at 6X the rate as the neural data, there is typically multiple data points we can choose for the coordinate of a trace\n",
    "## For simplicity, we will pick the coordinate that exactly matches the time point of the trace\n",
    "## In the future we can do some averaging or picking the median, etc. \n",
    "\n",
    "trace_coordinate_indexes = []\n",
    "good_points_index = good_points.index.values\n",
    "\n",
    "for time in tqdm(trimmed_good_cell_trace_data.index.values):\n",
    "    coordinate_index = np.where(good_points_index == time)[0]\n",
    "\n",
    "    trace_coordinate_indexes.extend(coordinate_index)\n",
    "\n",
    "trace_coordinates = coordinates[trace_coordinate_indexes]\n",
    "\n",
    "trimmed_good_cell_trace_data.insert(0, 'Coordinate_Index', trace_coordinate_indexes)\n",
    "trimmed_good_cell_trace_data.insert(1, 'Coordinates', trace_coordinates)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398c9fab35bf711d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## Save the paired coordinates - trace data\n",
    "\n",
    "folder_stem = ['EPM_Analysis', 'PreProcessedData']\n",
    "folder = test_path.joinpath(*folder_stem)\n",
    "folder = folder.parts\n",
    "\n",
    "DewanIOhandler.save_data_to_disk(trimmed_good_cell_trace_data, 'trimmed_good_cell_trace_data', fileHeader, folder, True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2c8dc5974fbab93",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
