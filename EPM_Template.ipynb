{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Dewan Lab EPM Analysis",
   "metadata": {
    "collapsed": false
   },
   "id": "1471a0c2b0c3e8ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5d20e6bdd90448"
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import ndimage\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from dewan_calcium import plotting, deconv\n",
    "from dewan_calcium.helpers import IO, parse_json, EPM\n",
    "from dewan_calcium.helpers.project_folder import ProjectFolder\n",
    "\n",
    "print(\"Importing required packages complete!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1B: User Configurables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbadb82b6bdf09c"
  },
  {
   "cell_type": "code",
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "EXPERIMENT_TIME = 10\n",
    "LED_CUTOFF = 0.95\n",
    "ENDOSCOPE_FRAMERATE = 10  # Hz\n",
    "PSEUDOTRIAL_LEN_S = 2\n",
    "\n",
    "# Endoscope Framerate = 10Hz\n",
    "# Rise time = 80ms\n",
    "# Decay time = 400ms\n",
    "\n",
    "peak_args = {\n",
    "    'decay': 400, #ms \n",
    "    'rise': 80,  #ms\n",
    "    'ISI': 100, # inter-spike-interval; ms\n",
    "    'height': 1 # 1 SD\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17c61cc38601c39",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Project Folder to Gather and Hold all the File Paths\n",
    "\n",
    "#test_path = Path(\"/mnt/dev/Test_Data/Odor/VGLUT-20\")  # On Fedora\n",
    "#test_path = Path(\"C:\\\\Projects\\\\Test_Data\\\\EPM\\\\VGLUT-20\")  # On Desktop\n",
    "#test_path = Path('D:/Test_Data/EPM/VGLUT-20') # Laptop Windows\n",
    "test_path = Path('D:\\\\Projects\\\\Test_Data\\\\EPM\\\\VGLUT-20') # C474B\n",
    "\n",
    "project_folder = ProjectFolder('EPM', project_dir=test_path)\n",
    "file_header = animal + '-' + date + '-'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b153d57361969394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If this is the first time the project folder has been created,\n",
    "# move the files to the appropriate directories and then run this cell, otherwise skip this cel\n",
    "project_folder.get_data()"
   ],
   "id": "8335d89603fe71ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get settings from imaging session and display them for the user\n",
    "\n",
    "gain, LED_power, focal_planes = parse_json.get_session_settings(project_folder.raw_data_dir.session_json_path)\n",
    "\n",
    "print(f'Recording Gain: {gain}')\n",
    "print(f'LED Power: {LED_power}')\n",
    "print(f'Focal Plane(s): {focal_planes}')"
   ],
   "id": "4181d09c235c41ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2A: Import and pre-process the raw data",
   "id": "b8e0375d9126c67a"
  },
  {
   "cell_type": "code",
   "source": [
    "#STEP 2A.1: LOAD DLC DATA\n",
    "\n",
    "tracked_points = pd.read_hdf(project_folder.raw_data_dir.points_h5_path)  # Load tracked points\n",
    "labeled_video = cv2.VideoCapture(str(project_folder.raw_data_dir.labeled_video_path))  # Load Video\n",
    "VIDEO_FPS = labeled_video.get(cv2.CAP_PROP_FPS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9b3d146c77c791e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#STEP 2A.2: LOAD INSCOPIX DATA\n",
    "\n",
    "cell_trace_data = pd.read_csv(project_folder.inscopix_dir.cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(project_folder.inscopix_dir.GPIO_path, header=0, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(project_folder.inscopix_dir.props_path, header=0, engine='pyarrow')\n",
    "cell_outlines = parse_json.get_outline_coordinates(project_folder.inscopix_dir.contours_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abd14e642db457ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2A.2: PREPROCESSING\n",
    "\n",
    "# STEP 2A.2.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data = cell_trace_data.drop([0])\n",
    "\n",
    "# STEP 2A.2.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data = cell_trace_data.set_index(cell_trace_data.columns[0]) \n",
    "\n",
    "# STEP 2A.2.3: Remove spaces from column names and contents\n",
    "cell_trace_data.columns = cell_trace_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data.columns = GPIO_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data['ChannelName'] = GPIO_data['ChannelName'].str.replace(\" \", \"\")\n",
    "\n",
    "# STEP 2A.2.4: Reduce properties to only include the cells with only one component\n",
    "all_cell_props = all_cell_props[all_cell_props['NumComponents']==1]  # We only want cells that have one component\n",
    "all_cell_props = all_cell_props.drop(columns='Status').reset_index(drop=True)\n",
    "cell_names = all_cell_props['Name'].values\n",
    "\n",
    "# STEP 2A.2.5: PARSE GPIO DATA\n",
    "sniff_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-1\"].reset_index(drop=True)\n",
    "FV_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-2\"].reset_index(drop=True)\n",
    "\n",
    "# OPTIONAL UNUSED DATA\n",
    "# running_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-3\"]  # Running Wheel Data\n",
    "# lick_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-4\"]  # Lick Data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c367711c48588a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2A.3: PREPROCESSING DLC Data\n",
    "\n",
    "cols = ['mouse_x', 'mouse_y', 'mouse_p', 'led_x', 'led_y', 'led_p'] \n",
    "# Reset the column names to something sensible\n",
    "tracked_points.columns = cols "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f314d311576ad6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2B: Manual Curation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e21d1f96278b274b"
  },
  {
   "cell_type": "code",
   "source": [
    "from dewan_manual_curation import dewan_manual_curation\n",
    "# STEP 2B.2: Run ManualCuration GUI\n",
    "curated_cells = dewan_manual_curation.launch_gui(project_folder_override=project_folder, cell_trace_data_override=cell_trace_data, cell_props_override=all_cell_props, cell_contours_override=cell_outlines)\n",
    "if curated_cells is None:\n",
    "    print('Error, no good cells selected!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d6c2c8fc4f07b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2C: Apply Manual Curation Results and Additional Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba514ce06958860"
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2C.1: Filter all data by the GoodCells identified in ManualCuration\n",
    "curated_cell_props = all_cell_props[all_cell_props['Name'].isin(curated_cells)].reset_index(drop=True)\n",
    "curated_trace_data = cell_trace_data[curated_cells]\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d4ee4dc735b1d81",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2D: Pickle and Save all preprocessed data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bec801c85b27c1bb"
  },
  {
   "cell_type": "code",
   "source": [
    "# Pickle the reorganized CellTraceData incase its needed later\n",
    "# Saves Cell Traces, GPIO, Odor List, Sniff, FV data, Good Cell Properties, Good Cells, and the labeled max projection\n",
    "# Once these have been saved, they don't need to be re-run on the same data again unless the data itself is changed\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(curated_trace_data, 'curated_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(GPIO_data, 'GPIO_data', file_header, folder)\n",
    "IO.save_data_to_disk(FV_data, 'FV_data', file_header, folder)\n",
    "IO.save_data_to_disk(curated_cell_props, 'curated_cell_props', file_header, folder)\n",
    "IO.save_data_to_disk(sniff_data, 'sniff_table', file_header, folder)\n",
    "\n",
    "IO.save_data_to_disk(tracked_points, 'tracked_points', file_header, folder)\n",
    "IO.save_data_to_disk(VIDEO_FPS, 'VIDEO_FPS', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "176c5be1ba73ca5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Opens the saved pickle files.  If the files have already been saved, code can be re-run\n",
    "# starting from this point\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "curated_trace_data = IO.load_data_from_disk('curated_trace_data', file_header, folder)\n",
    "GPIO_data = IO.load_data_from_disk('GPIO_data', file_header, folder)\n",
    "FV_data = IO.load_data_from_disk('FV_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "sniff_data = IO.load_data_from_disk('sniff_table', file_header, folder)\n",
    "\n",
    "cell_names = curated_cell_props['Name']  # List of cells, referenced periodically\n",
    "\n",
    "tracked_points = IO.load_data_from_disk('tracked_points', file_header, folder)\n",
    "VIDEO_FPS = IO.load_data_from_disk('VIDEO_FPS', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c706c8b64d42488",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# There may be an instance where the model erroneously identified the LED for very short time periods\n",
    "# find_index_bins returns the LED on and off bins (anywhere led_p > 0.98)\n",
    "# true_led_bin ensures that the \"true\" start bin is selected and the \"end\" bin is not erroneously selected\n",
    "\n",
    "LED_indexes = tracked_points.index[tracked_points['led_p'] > LED_CUTOFF].values\n",
    "\n",
    "led_bins = EPM.find_index_bins(LED_indexes)\n",
    "true_led_bin = EPM.get_true_bin_index(led_bins, len(tracked_points))\n",
    "\n",
    "led_on = true_led_bin[0] # The first instance where the LED is 'on'\n",
    "experiment_frames = int(VIDEO_FPS * 60 * EXPERIMENT_TIME)  # FPS * 60 s/min * experiment length in minutes --> number of frames\n",
    "end_frame = led_on + experiment_frames\n",
    "good_points = tracked_points.iloc[led_on:end_frame] # Subset the frames from LED_ON -> EXPERIMENT_TIME minutes later\n",
    "good_points = good_points.reset_index(drop=True) # Reset the index\n",
    "\n",
    "# Get X, Y coordinates, cast to int, and combine them into tuples\n",
    "head_x = good_points['mouse_x'].astype(int)\n",
    "head_y = good_points['mouse_y'].astype(int)\n",
    "coordinates = [list(item) for item in zip(head_x, head_y)]\n",
    "coordinates = np.array(coordinates)"
   ],
   "id": "e1e30f041e79b4f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Run this cell to interpolate large distance jumps in the DLC tracking data\n",
    "thresh, num_jumps, coordinates = EPM.interpolate_DLC_coordinates(coordinates) # TODO: Empirically determine the jump threshold \n",
    "print(f\"There were {num_jumps} jumps that required interpolation.\")\n",
    "print(f\"The interpolation threshold used was {thresh}\")"
   ],
   "metadata": {},
   "id": "3936e033ac8d7e48",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 3A: Parses the final valve data to identify when the final valve is open vs when it is closed based on TTL pulse from Arduino.\n",
    "# In the EPM experiment, there is no final valve. However, we are using the same sync signal as used in the odor experiments to signal when the LED is triggered\n",
    "\n",
    "FV_values = FV_data['Value'].astype(float).values # Get FV Values\n",
    "num_values = len(FV_values)\n",
    "valve_status = 0\n",
    "FV_on_indexes = []\n",
    "FV_off_indexes = []\n",
    "for i in trange((num_values - 1), desc=\"Processing: \"):\n",
    "    valve_val_diff = FV_values[i + 1] - FV_values[i]\n",
    "\n",
    "    if valve_status == 0:    # Start with valve off\n",
    "        if valve_val_diff > 10000: # If the difference is a very large positive number, the valve opened\n",
    "            FV_on_indexes.append(i + 1)\n",
    "            valve_status = 1 # Set valve state to open\n",
    "    else:\n",
    "        if valve_val_diff < -10000: # If the difference is a very laarge negative number, the valve closed\n",
    "            FV_off_indexes.append(i)\n",
    "            valve_status = 0 # Set valve state to closed\n",
    "\n",
    "FV_indexes = pd.DataFrame(zip(FV_on_indexes, FV_off_indexes), columns=['On', 'Off'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5505d5ba98ede822",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "experiment_start_index = FV_indexes['On'][0]\n",
    "FV_timestamps = FV_data['Time(s)']\n",
    "trial_start_time = FV_timestamps[experiment_start_index]  # Trial start time in unix time (s)\n",
    "trial_end_time = trial_start_time + (EXPERIMENT_TIME * 60)  # End time is whatever the duration of the experiment was in minutes\n",
    "\n",
    "cell_trace_times = curated_trace_data.index.values\n",
    "\n",
    "cell_trace_on_index = np.where(cell_trace_times <= trial_start_time)[0][-1]\n",
    "cell_trace_off_index = np.where(cell_trace_times <= trial_end_time)[0][-1]  # We can't overshoot otherwise the coordinate will not match, so we may drop a single frame\n",
    "\n",
    "trimmed_trace_data = curated_trace_data.iloc[cell_trace_on_index:cell_trace_off_index, :]\n",
    "\n",
    "trimmed_cell_trace_times = trimmed_trace_data.index.values\n",
    "shifted_cell_trace_times = np.subtract(trimmed_cell_trace_times, trimmed_cell_trace_times[0])\n",
    "rounded_cell_trace_times = np.round(shifted_cell_trace_times, 2)\n",
    "\n",
    "trimmed_trace_data.index = rounded_cell_trace_times\n",
    "\n",
    "good_points_index = good_points.index.values\n",
    "good_points_time = np.divide(good_points_index, VIDEO_FPS)\n",
    "good_points.index = good_points_time"
   ],
   "id": "60552b9f3540b418",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Align Cell Traces with the DLC Data\n",
    "## Since the DLC data is typically recorded at 6X the rate as the neural data, there is typically multiple data points we can choose for the coordinate of a trace\n",
    "## For simplicity, we will pick the coordinate that exactly matches the time point of the trace\n",
    "## In the future we can do some averaging or picking the median, etc. \n",
    "\n",
    "trace_coordinate_indexes = []\n",
    "good_points_index = good_points.index.values\n",
    "\n",
    "for time in tqdm(trimmed_trace_data.index):  # Check each \n",
    "    coordinate_index = np.where(good_points.index <= time)[0][-1]\n",
    "    trace_coordinate_indexes.append(coordinate_index)\n",
    "\n",
    "trace_coordinates = coordinates[trace_coordinate_indexes]\n",
    "trace_coordinates = trace_coordinates.tolist()\n",
    "trimmed_trace_data.insert(0, 'Coordinate_Index', trace_coordinate_indexes)\n",
    "trimmed_trace_data.insert(0, 'Coordinates', trace_coordinates)"
   ],
   "id": "fc586f8e96da691c",
   "metadata": {},
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Save the paired coordinates - trace data\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(trimmed_trace_data, 'trimmed_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(true_led_bin, 'true_led_bin', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2c8dc5974fbab93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Load the ROI selection data\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "labeled_video = cv2.VideoCapture(str(project_folder.raw_data_dir.labeled_video_path)) \n",
    "trimmed_trace_data = IO.load_data_from_disk('trimmed_trace_data', file_header, folder)\n",
    "true_led_bin = IO.load_data_from_disk('true_led_bin', file_header, folder)\n",
    "led_on = true_led_bin[0]"
   ],
   "id": "c8dee071f4a23228",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "EPM.display_roi_instructions()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bd66fbad02ae9963",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%matplotlib qt  \n",
    "# Opens the matplotlib window using the QT backend\n",
    "\n",
    "labeled_video.set(cv2.CAP_PROP_POS_FRAMES, led_on - 1) # Pull the frame that is our actual start\n",
    "_, background_image = labeled_video.read()\n",
    "\n",
    "arm_coordinates = EPM.get_arm_rois(background_image)\n",
    "\n",
    "# Switch back to using inline displays\n",
    "%matplotlib inline\n",
    "\n",
    "individual_regions, original_regions = EPM.get_region_polygons(arm_coordinates)  \n",
    "# ([open_arm_1, open_arm_2, closed_arm_1, closed_arm_2, center_polygon], [open_arm, closed_arm, center])\n",
    "\n",
    "fig, ax = plotting.plot_epm_roi(original_regions, background_image)  # TODO: Ensure that the order of arms is still o1, o2, c1, c2 if the EPM is rotated 90 degrees but labeled correctly"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1e44c3c576c1c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Save the ROIs and image\n",
    "folder = project_folder.analysis_dir.figures_dir.subdir('EPM_ROI')\n",
    "\n",
    "image_path = folder.joinpath('EPM_ROI.pdf')\n",
    "fig.savefig(str(image_path), dpi=600)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.subdir('EPM_ROI')\n",
    "IO.save_data_to_disk(arm_coordinates, 'arm_coordinates', file_header, folder)\n",
    "IO.save_data_to_disk(individual_regions, 'individual_regions', file_header, folder)\n",
    "IO.save_data_to_disk(original_regions, 'original_regions', file_header, folder)\n",
    "IO.save_data_to_disk(background_image, 'background_image', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b8d8a425e81e129",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## Load the ROIs and image\n",
    "folder = project_folder.analysis_dir.preprocess_dir.subdir('EPM_ROI')\n",
    "arm_coordinates = IO.load_data_from_disk('arm_coordinates', file_header, folder)\n",
    "individual_regions = IO.load_data_from_disk('individual_regions', file_header, folder)\n",
    "original_regions = IO.load_data_from_disk('original_regions', file_header, folder)\n",
    "background_image = IO.load_data_from_disk('background_image', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "trimmed_trace_data = IO.load_data_from_disk('trimmed_trace_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "id": "dc876c81d6ffe3a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Get region for each time point and distance from occupied region\n",
    "animal_coordinates = trimmed_trace_data['Coordinates']\n",
    "coordinate_locations, region_indexes = EPM.get_regions(animal_coordinates, individual_regions) # What region each (x, y) is in"
   ],
   "metadata": {},
   "id": "969025068905880",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Run this cell if you would like to interpolate any position that fell outside the 5 regions\n",
    "void_indexes = np.where(coordinate_locations == \"The_Void\")[0]  # \"The_Void\" is the location assigned to points that fall outside of the five regions (open1, open2, closed1, closed2, center). This can occur if the animal looks over the side of the open arms\n",
    "void_index_bins = EPM.find_index_bins(void_indexes)\n",
    "coordinate_locations, region_indexes = EPM.replace_the_void(coordinate_locations, region_indexes, void_index_bins)"
   ],
   "id": "9879ea179baa99d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Optional: Run this cell if you would like to calculate the \"distance\" into the arm the animal has traveled\n",
    "coordinate_pairs = list(zip(animal_coordinates, region_indexes))\n",
    "distances = EPM.get_distances(individual_regions, coordinate_pairs)  # Return distance from animal -> occupied region\n",
    "# distances = EPM.normalize_distance(individual_regions, coordinate_locations, distances)\n",
    "# If desired, the distances can be normalized to the length of the arms. All positions become 'percentages' of the length along the arm\n",
    "trimmed_trace_data.insert(0, 'Distance', distances)"
   ],
   "id": "2fa976779064c28d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Add animal Location to the main list of trace data\n",
    "trimmed_trace_data.insert(0, 'Location', coordinate_locations)"
   ],
   "id": "6f0fca04d71fcbfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## PSEUDOTRIAL COLLECTION\n",
    "# Find transitions from region -> region\n",
    "# Gather all visits per each region\n",
    "# Calculate some statistics about our 'pseudotrials'\n",
    "\n",
    "animal_locations = trimmed_trace_data['Location']\n",
    "transitions, arm_indexes = EPM.find_region_transitions(animal_locations)"
   ],
   "id": "609992a8e527d75f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "pseudotrials, trial_stats = EPM.get_pseudotrials(arm_indexes, transitions, PSEUDOTRIAL_LEN_S, ENDOSCOPE_FRAMERATE)\n",
    "\n",
    "EPM.print_pseudotrial_stats(pseudotrials, trial_stats)"
   ],
   "id": "e4fa56fc7f4c1d09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pseudotrial_traces = {\n",
    "    'open1': [],\n",
    "    'open2': [],\n",
    "    'closed1': [],\n",
    "    'closed2': []\n",
    "}\n",
    "\n",
    "frames_per_pseudotrial = int(np.floor(PSEUDOTRIAL_LEN_S * ENDOSCOPE_FRAMERATE)) \n",
    "\n",
    "for arm in pseudotrials:\n",
    "    arm_visits = pseudotrials[arm]\n",
    "    \n",
    "    for visit in arm_visits:\n",
    "        start_index = visit['start']\n",
    "        end_index = start_index + frames_per_pseudotrial\n",
    "        traces = trimmed_trace_data[cell_names].iloc[start_index:end_index]\n",
    "        # We first grab the columns for the cells and then grab the rows for our trial\n",
    "        pseudotrial_traces[arm].append(traces)"
   ],
   "id": "49f63580fa9f64bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pseudotrial_means = {\n",
    "    'open1': pd.DataFrame(),\n",
    "    'open2': pd.DataFrame(),\n",
    "    'closed1': pd.DataFrame(),\n",
    "    'closed2': pd.DataFrame(),\n",
    "}\n",
    "\n",
    "for arm in pseudotrial_means:\n",
    "    for trial in pseudotrial_traces[arm]:\n",
    "        pseudotrial_means[arm] = pd.concat((pseudotrial_means[arm], trial.mean(axis=0)), axis=1)\n",
    "    \n",
    "    pseudotrial_means[arm] = pseudotrial_means[arm].T\n",
    "    pseudotrial_means[arm] = pseudotrial_means[arm].reset_index(drop=True)"
   ],
   "id": "6fe4ab81d041f50b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('pseudotrials')\n",
    "\n",
    "IO.save_data_to_disk(pseudotrials, 'pseudotrials', file_header, folder)\n",
    "IO.save_data_to_disk(trial_stats, 'trial_stats', file_header, folder)\n",
    "IO.save_data_to_disk(transitions, 'transitions', file_header, folder)\n",
    "IO.save_data_to_disk(arm_indexes, 'arm_indexes', file_header, folder)\n",
    "IO.save_data_to_disk(pseudotrial_traces, 'pseudotrial_traces', file_header, folder)\n",
    "IO.save_data_to_disk(pseudotrial_means, 'pseudotrial_means', file_header, folder)"
   ],
   "id": "3153e57c56bd5167",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('pseudotrials')\n",
    "\n",
    "pseudotrials = IO.load_data_from_disk('pseudotrials', file_header, folder)\n",
    "trial_stats = IO.load_data_from_disk('trial_stats', file_header, folder)\n",
    "transitions = IO.load_data_from_disk('transitions', file_header, folder)\n",
    "arm_indexes = IO.load_data_from_disk('arm_indexes', file_header, folder)\n",
    "pseudotrial_traces = IO.load_data_from_disk('pseudotrial_traces', file_header, folder)\n",
    "pseudotrial_means = IO.load_data_from_disk('pseudotrial_means', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "id": "f4365867fa62742c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dewan_calcium import AUROC\n",
    "groups = (['open1', 'open2'], ['closed1', 'closed2'])\n",
    "# Open -> 0, closed -> 1\n",
    "AUROC_results = AUROC.EPM_auroc(pseudotrial_means, groups, cell_names)"
   ],
   "id": "387a04ecd155097e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "IO.save_data_to_disk(AUROC_results, 'AUROC_results', file_header, folder)"
   ],
   "id": "b13254ce9ce8cfd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "AUROC_results = IO.load_data_from_disk('AUROC_results', file_header, folder)"
   ],
   "id": "9e607a4555a1c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#auroc_output = pd.DataFrame(columns=['auROC', 'direction_index', 'bounds', 'significant'])\n",
    "auroc_output = []\n",
    "for cell in AUROC_results:\n",
    "    data = AUROC_results[cell]\n",
    "    direction_index = round(2 * (data['auroc'] - 0.5), 2)\n",
    "    auroc = round(data['auroc'], 2)\n",
    "    bounds = (data['lb'], data['ub'])\n",
    "    significance = data['significance']\n",
    "\n",
    "    new_row = [auroc, direction_index, bounds, significance]\n",
    "    auroc_output.append(new_row)\n",
    "    \n",
    "auroc_output = pd.DataFrame(auroc_output, index=cell_names, columns=['auROC', 'direction_index', 'bounds', 'significant'])"
   ],
   "id": "8a00def0eba4a022",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# TODO: Add pseudotrial statistics to the excel output",
   "id": "96b5eb401350a950",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.path\n",
    "file_name = f'{file_header}EPM_data_output.xlsx'\n",
    "file_path = folder.joinpath(file_name)\n",
    "auroc_output.to_excel(file_path)"
   ],
   "id": "1eb4e6126b4cf096",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "auroc_vals = [AUROC_results[cell]['auroc'] for cell in AUROC_results]\n",
    "auroc_vals = np.array(auroc_vals)\n",
    "direction_indexes = 2 * (auroc_vals - 0.5)\n",
    "fig, ax = plt.subplots(1,2, figsize=(8, 3))\n",
    "ax[0].hist(direction_indexes, bins=20)\n",
    "ax[1].hist(auroc_vals, color='r', bins=20)\n",
    "minmax = [min(direction_indexes), max(direction_indexes)]\n",
    "minmax2 = [min(auroc_vals), max(auroc_vals)]\n",
    "\n",
    "ax[0].set_xticks(np.linspace(-1, 1, 21))\n",
    "ax[1].set_xticks(np.linspace(0, 1, 21))\n",
    "\n",
    "ax[0].set_xlim(minmax)\n",
    "ax[1].set_xlim(minmax2)\n",
    "\n",
    "ax[0].tick_params(axis='x', labelrotation=50)\n",
    "ax[1].tick_params(axis='x', labelrotation=50)\n",
    "\n",
    "ax[0].set_title('Direction Indices')\n",
    "ax[1].set_title('auROC Values')\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_dir = project_folder.analysis_dir.figures_dir.subdir('AUROC')\n",
    "fig_path = fig_dir.joinpath('auROC_distribution.pdf')\n",
    "fig.savefig(fig_path, dpi=600)\n",
    "plt.close(fig)\n",
    "\n",
    "for cell in tqdm(cell_names):\n",
    "    try:\n",
    "        results = AUROC_results[cell]\n",
    "        ub = results['ub']\n",
    "        lb = results['lb']\n",
    "        auroc = results['auroc']\n",
    "        shuffle = results['shuffle']\n",
    "        significance = results['significance']\n",
    "        \n",
    "        relaxed_bounds = np.percentile(shuffle, [5, 95])\n",
    "        lb_r, ub_r = relaxed_bounds\n",
    "        \n",
    "        fig, ax = plt.subplots()\n",
    "        ax.hist(shuffle, color='gray', bins=10)\n",
    "        ax.axvline(x=ub, color='blue')\n",
    "        ax.axvline(x=lb, color='blue')\n",
    "        ax.axvline(x=ub_r, color='green')\n",
    "        ax.axvline(x=lb_r, color='green')\n",
    "        ax.axvline(x=auroc, color='red')\n",
    "        \n",
    "        if significance in (-1, 1):\n",
    "            ax.set_xlabel('Significant!')\n",
    "        \n",
    "        fig.suptitle(f'{cell} - {round(auroc, 3)}')\n",
    "        \n",
    "        save_dir = project_folder.analysis_dir.figures_dir.subdir('AUROC')\n",
    "        file_path = save_dir.joinpath(f'{cell}.pdf')\n",
    "        fig.savefig(file_path, dpi=600)\n",
    "        plt.close(fig)    \n",
    "    except Exception as e: # yes, this is bad; its okay\n",
    "        print(f'Error plotting {cell}')\n",
    "        print(e)\n",
    "        "
   ],
   "id": "6e44933452e34ead",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# closed_distances = smoothed_traces[np.isin(smoothed_traces['Location'], ['closed1', 'closed2'])]['Distance'].values\n",
    "# open_distances = smoothed_traces[np.isin(smoothed_traces['Location'], ['open1', 'open2'])]['Distance'].values * -1\n",
    "# smoothed_traces.loc[np.isin(smoothed_traces['Location'], ['open1', 'open2']), \"Distance\"] *= -1\n",
    "# smoothed_traces.loc[np.isin(smoothed_traces['Location'], ['center']), \"Distance\"] = 0\n",
    "# from dewan_calcium import AUROC\n",
    "# import matplotlib.pyplot as plt\n",
    "# cell_avg_distances = {}\n",
    "# for cell in tqdm(cell_names):\n",
    "#\n",
    "#     spikes = fake_spike_indexes[cell]\n",
    "#     null_distances = []\n",
    "#     num_spikes = len(spikes)\n",
    "#\n",
    "#     for _ in range(1000):\n",
    "#         random_spike_indices = np.random.randint(0, len(smoothed_traces['Distance'].values), num_spikes)\n",
    "#         random_distances = smoothed_traces['Distance'].values[random_spike_indices]\n",
    "#         avg_distance = np.mean(random_distances)\n",
    "#         null_distances.append(avg_distance)\n",
    "#\n",
    "#     null_distances = np.array(null_distances)\n",
    "#     distance = smoothed_traces.iloc[spikes]['Distance']\n",
    "#     cell_avg_distance = np.mean(distance)\n",
    "#     ptile = np.percentile(null_distances, [1, 99])\n",
    "#     cell_percentile = AUROC.compute_percentile(cell_avg_distance, null_distances)\n",
    "#     # print(ptile, cell_percentile)\n",
    "#\n",
    "#     fig, ax = plt.subplots()\n",
    "#\n",
    "#     ax.hist(null_distances)\n",
    "#     ax.vlines(x=cell_avg_distance, ymin=0, ymax=350, color='r')\n",
    "#     ax.vlines(x=ptile, ymin=0, ymax=350, color='magenta')\n",
    "#     fig.suptitle(f'{cell} - {cell_percentile*100}')\n",
    "#     cell_avg_distances[cell] = cell_avg_distance\n",
    "# coordinates = smoothed_traces['Coordinate']\n",
    "# image_shape = image.shape\n",
    "#\n",
    "# combined_activity_heatmap, cell_heatmaps = EPM.generate_activity_heatmap(coordinates, fake_spike_indexes, cell_names, image_shape)\n",
    "# line_coordinates = EPM.generate_position_lines(coordinates)\n",
    "# folder = project_folder.analysis_dir.figures_dir.path.joinpath('heatmaps')\n",
    "# folder.mkdir()\n",
    "#\n",
    "# filtered_spike_heatmap = ndimage.gaussian_filter(combined_activity_heatmap, sigma=1.5)\n",
    "#\n",
    "# for cell in cell_names:\n",
    "#     heatmap = cell_heatmaps[cell]\n",
    "#     filtered_heatmap = ndimage.gaussian_filter(heatmap, sigma=1.5)\n",
    "#     plotting.plot_activity_heatmap(filtered_heatmap, line_coordinates, image, cell, folder)\n",
    "#\n",
    "#\n",
    "# plotting.plot_activity_heatmap(filtered_spike_heatmap, line_coordinates, image, 'Combined', folder)  # Combined Heatmap"
   ],
   "id": "e45a7a8fef8c3bb9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
