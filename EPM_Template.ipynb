{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dewan Lab EPM Analysis\n",
    "## 0: Run once to create all needed directories at beginning of a project"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1471a0c2b0c3e8ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5d20e6bdd90448"
  },
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea0c658343a138ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from dewan_calcium.helpers import IO, parse_json, EPM\n",
    "from dewan_calcium.helpers.project_folder import ProjectFolder\n",
    "\n",
    "from dewan_calcium import plotting, deconv\n",
    "\n",
    "from dewan_manual_curation import dewan_manual_curation\n",
    "\n",
    "# from roipoly import MultiRoi  ## Must be installed from GitHub as the PyPi version is obsolete; pip install git+https://github.com/jdoepfert/roipoly.py"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1B: User Configurables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbadb82b6bdf09c"
  },
  {
   "cell_type": "code",
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "EXPERIMENT_TIME = 10"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17c61cc38601c39",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Project Folder to Gather and Hold all the File Paths\n",
    "\n",
    "#test_path = Path(\"/mnt/dev/Test_Data/Odor/VGLUT-20\")  # On Fedora\n",
    "test_path = Path(\"C:\\\\Projects\\\\Test_Data\\\\EPM\\\\VGLUT-20\")  # On Desktop\n",
    "\n",
    "project_folder = ProjectFolder(project_dir=test_path)\n",
    "file_header = animal + '-' + date + '-'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b153d57361969394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If this is the first time the project folder has been created,\n",
    "# move the files to the appropriate directories and then run this cell, otherwise skip this cel\n",
    "project_folder.get_data()"
   ],
   "id": "8335d89603fe71ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get settings from imaging session and display them for the user\n",
    "\n",
    "gain, LED_power, focal_planes = parse_json.get_session_settings(project_folder.raw_data_dir.session_json_path)\n",
    "\n",
    "print(f'Recording Gain: {gain}')\n",
    "print(f'LED_power: {LED_power}')\n",
    "print(f'LED_power: {focal_planes}')"
   ],
   "id": "4181d09c235c41ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 2A: Import and pre-process the raw data\n",
    "\n",
    "#### Copy DLC output .h5 file and labled video -> EPM_Analysis\\RawData"
   ],
   "id": "b8e0375d9126c67a"
  },
  {
   "cell_type": "code",
   "source": [
    "# New way that we should be grabbing the data\n",
    "\n",
    "#STEP 2A.1: LOAD DLC DATA\n",
    "# Read in data for processing.  Needs Cell Traces, Odor List, and GPIO file.\n",
    "\n",
    "tracked_points = pd.read_hdf(project_folder.raw_data_dir.points_h5_path)  # Load tracked points\n",
    "labeled_video = cv2.VideoCapture(str(project_folder.raw_data_dir.labeled_video_path))  # Load Video\n",
    "VIDEO_FPS = labeled_video.get(cv2.CAP_PROP_FPS)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9b3d146c77c791e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "#STEP 2A.2: LOAD INSCOPIX DATA\n",
    "\n",
    "cell_trace_data = pd.read_csv(project_folder.inscopix_dir.cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(project_folder.inscopix_dir.GPIO_path, header=0, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(project_folder.inscopix_dir.props_path, header=0, engine='pyarrow')\n",
    "cell_outlines = parse_json.get_outline_coordinates(project_folder.inscopix_dir.contours_path)  # TODO: remove cell keys from the json function"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abd14e642db457ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2A.2: PREPROCESSING\n",
    "\n",
    "# STEP 2A.2.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data = cell_trace_data.drop([0])\n",
    "\n",
    "# STEP 2A.2.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data = cell_trace_data.set_index(cell_trace_data.columns[0]) \n",
    "\n",
    "# STEP 2A.2.3: Remove spaces from column names and contents\n",
    "cell_trace_data.columns = cell_trace_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data.columns = GPIO_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data['ChannelName'] = GPIO_data['ChannelName'].str.replace(\" \", \"\")\n",
    "\n",
    "# STEP 2A.2.4: Reduce properties to only include the cells with only one component\n",
    "all_cell_props = all_cell_props[all_cell_props['NumComponents']==1]  # We only want cells that have one component\n",
    "all_cell_props = all_cell_props.drop(columns='Status').reset_index(drop=True)\n",
    "cell_names = all_cell_props['Name'].values\n",
    "\n",
    "# STEP 2A.2.5: PARSE GPIO DATA\n",
    "sniff_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-1\"].reset_index(drop=True)\n",
    "FV_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-2\"].reset_index(drop=True)\n",
    "\n",
    "# OPTIONAL UNUSED DATA\n",
    "# running_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-3\"]  # Running Wheel Data\n",
    "# lick_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-4\"]  # Lick Data\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c367711c48588a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2A.3: PREPROCESSING DLC Data\n",
    "\n",
    "cols = ['mouse_x', 'mouse_y', 'mouse_p', 'led_x', 'led_y', 'led_p'] \n",
    "# Reset the column names to something sensible\n",
    "tracked_points.columns = cols "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f314d311576ad6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2B: Manual Curation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e21d1f96278b274b"
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2B.2: Run ManualCuration GUI\n",
    "curated_cells = dewan_manual_curation.launch_gui(project_folder_override=project_folder, cell_trace_data_override=cell_trace_data, cell_contours_override=cell_outlines, cell_names_override=cell_names)\n",
    "if curated_cells is None:\n",
    "    print('Error, no good cells selected!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d6c2c8fc4f07b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2C: Apply Manual Curation Results and Additional Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba514ce06958860"
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2C.1: Filter all data by the GoodCells identified in ManualCuration\n",
    "curated_cell_props = all_cell_props[all_cell_props['Name'].isin(curated_cells)].reset_index(drop=True)\n",
    "curated_trace_data = cell_trace_data[curated_cells]\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d4ee4dc735b1d81",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2D: Pickle and Save all preprocessed data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bec801c85b27c1bb"
  },
  {
   "cell_type": "code",
   "source": [
    "# Pickle the reorganized CellTraceData incase its needed later\n",
    "# Saves Cell Traces, GPIO, Odor List, Sniff, FV data, Good Cell Properties, Good Cells, and the labeled max projection\n",
    "# Once these have been saved, they don't need to be re-run on the same data again unless the data itself is changed\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(curated_trace_data, 'curated_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(GPIO_data, 'GPIO_data', file_header, folder)\n",
    "IO.save_data_to_disk(FV_data, 'FV_data', file_header, folder)\n",
    "IO.save_data_to_disk(curated_cell_props, 'curated_cell_props', file_header, folder)\n",
    "IO.save_data_to_disk(sniff_data, 'sniff_table', file_header, folder)\n",
    "\n",
    "IO.save_data_to_disk(tracked_points, 'tracked_points', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "176c5be1ba73ca5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Opens the saved pickle files.  If the files have already been saved, code can be re-run\n",
    "# starting from this point\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "\n",
    "curated_trace_data = IO.load_data_from_disk('curated_trace_data', file_header, folder)\n",
    "GPIO_data = IO.load_data_from_disk('GPIO_data', file_header, folder)\n",
    "odor_data = IO.load_data_from_disk('odor_data', file_header, folder)\n",
    "odor_list = IO.load_data_from_disk('odor_list', file_header, folder)\n",
    "FV_data = IO.load_data_from_disk('FV_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "sniff_data = IO.load_data_from_disk('sniff_table', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']  # List of cells, referenced periodically\n",
    "\n",
    "tracked_points = IO.load_data_from_disk('tracked_points', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c706c8b64d42488",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# There may be an instance where the model erroneously identified the LED for very short time periods\n",
    "# find_led_start bins the possible LED on times (anywhere led_p > 0.98)\n",
    "# We then find the bin with the largest size, which means it has the most frames where the LED is identified\n",
    "# This is most likely the period where the experimenter turned on the LED\n",
    "led_bins = np.array(EPM.find_led_start(tracked_points))\n",
    "\n",
    "true_led_bin = np.argmax(np.subtract(led_bins[:, 1], led_bins[:,0]))\n",
    "\n",
    "led_on = led_bins[true_led_bin][0] # Find first row where the LED is 'on'\n",
    "experiment_frames = int(VIDEO_FPS * 60 * EXPERIMENT_TIME)  # FPS * 60 s/min * experiment length in minutes --> number of frames\n",
    "end_frame = led_on + experiment_frames\n",
    "\n",
    "good_points = tracked_points.iloc[led_on:end_frame] # Subset the frames from LED_ON -> ten minutes later\n",
    "good_points.reset_index(drop=True, inplace=True) # Reset the index\n",
    "\n",
    "# Get X, Y coordinates, cast to int, and combine them into tuples\n",
    "head_x = good_points['mouse_x'].astype(int)\n",
    "head_y = good_points['mouse_y'].astype(int)\n",
    "coordinates = np.fromiter(zip(head_x, head_y), dtype=object)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c77b4569ed5cad3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 3A: Parses the final valve data to identify when the final valve is open vs when it is closed based on TTL pulse from Arduino.\n",
    "FV_values = FV_data['Value'].astype(float).values # Get FV Values\n",
    "num_values = len(FV_values)\n",
    "valve_status = 0\n",
    "FV_on_indexes = []\n",
    "FV_off_indexes = []\n",
    "for i in trange((num_values - 1), desc=\"Processing: \"):\n",
    "    valve_val_diff = FV_values[i + 1] - FV_values[i]\n",
    "\n",
    "    if valve_status == 0:    # Start with valve off\n",
    "        if valve_val_diff > 10000: # If the difference is a very large positive number, the valve opened\n",
    "            FV_on_indexes.append(i + 1)\n",
    "            valve_status = 1 # Set valve state to open\n",
    "    else:\n",
    "        if valve_val_diff < -10000: # If the difference is a very laarge negative number, the valve closed\n",
    "            FV_off_indexes.append(i)\n",
    "            valve_status = 0 # Set valve state to closed\n",
    "\n",
    "FV_indexes = pd.DataFrame(zip(FV_on_indexes, FV_off_indexes), columns=['On', 'Off'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5505d5ba98ede822",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "experiment_start_index = FV_indexes['On'][0]\n",
    "FV_timestamps = FV_data['Time(s)']\n",
    "trial_start_time = FV_timestamps[experiment_start_index]  # Trial start time in unix time (s)\n",
    "trial_end_time = trial_start_time + (EXPERIMENT_TIME * 60)  # End time is whatever the duration of the experiment was in minutes\n",
    "\n",
    "cell_trace_times = curated_trace_data.index.values\n",
    "\n",
    "cell_trace_on_index = np.where(cell_trace_times <= trial_start_time)[0][-1]\n",
    "cell_trace_off_index = np.where(cell_trace_times <= trial_end_time)[0][-1]  # We can't overshoot otherwise the coordinate will not match, so we may drop a single frame"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53656167eb7c08ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "trimmed_trace_data = curated_trace_data.iloc[cell_trace_on_index:cell_trace_off_index, :]\n",
    "\n",
    "trimmed_cell_trace_times = trimmed_trace_data.index.values\n",
    "shifted_cell_trace_times = np.subtract(trimmed_cell_trace_times, trimmed_cell_trace_times[0])\n",
    "rounded_cell_trace_times = np.round(shifted_cell_trace_times, 2)\n",
    "\n",
    "trimmed_trace_data.index = rounded_cell_trace_times\n",
    "\n",
    "good_points_index = good_points.index.values\n",
    "good_points_time = np.divide(good_points_index, VIDEO_FPS)\n",
    "good_points.index = good_points_time"
   ],
   "id": "60552b9f3540b418",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Align Cell Traces with the DLC Data\n",
    "## Since the DLC data is typically recorded at 6X the rate as the neural data, there is typically multiple data points we can choose for the coordinate of a trace\n",
    "## For simplicity, we will pick the coordinate that exactly matches the time point of the trace\n",
    "## In the future we can do some averaging or picking the median, etc. \n",
    "\n",
    "trace_coordinate_indexes = []\n",
    "good_points_index = good_points.index.values\n",
    "\n",
    "for time in tqdm(trimmed_good_cell_trace_data.index.values):\n",
    "    coordinate_index = np.where(good_points_index == time)[0]\n",
    "\n",
    "    trace_coordinate_indexes.extend(coordinate_index)\n",
    "\n",
    "trace_coordinates = coordinates[trace_coordinate_indexes]\n",
    "\n",
    "trimmed_good_cell_trace_data.insert(0, 'Coordinate_Index', trace_coordinate_indexes)\n",
    "trimmed_good_cell_trace_data.insert(1, 'Coordinates', trace_coordinates)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "398c9fab35bf711d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Save the paired coordinates - trace data\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(trimmed_good_cell_trace_data, 'trimmed_good_cell_trace_data', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2c8dc5974fbab93",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "EPM.display_roi_instructions()",
   "metadata": {
    "collapsed": false
   },
   "id": "bd66fbad02ae9963",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "%matplotlib qt  \n",
    "# Opens the matplotlib window using the QT backend\n",
    "\n",
    "labeled_video.set(cv2.CAP_PROP_POS_FRAMES, led_on - 1) # Pull the frame that is our actual start\n",
    "_, image = labeled_video.read()\n",
    "\n",
    "arm_coordinates = EPM.get_arm_rois(image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d31587013d1bfad9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "individual_regions, original_regions = EPM.get_region_polygons(arm_coordinates)  \n",
    "# ([open_arm_1, open_arm_2, closed_arm_1, closed_arm_2, center_polygon], [open_arm, closed_arm, center])\n",
    "\n",
    "%matplotlib inline\n",
    "# Switch back to using inline displays\n",
    "fig, ax = plotting.plot_epm_roi(original_regions, image)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1e44c3c576c1c0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "## Save the ROIs and image\n",
    "folder = project_folder.analysis_dir.figures_dir.path\n",
    "\n",
    "image_path = folder.joinpath('EPM_ROI.pdf')\n",
    "\n",
    "fig.savefig(str(image_path), dpi=600)\n",
    "\n",
    "IO.save_data_to_disk(arm_coordinates, 'arm_coordinates', file_header, folder)\n",
    "IO.save_data_to_disk(individual_regions, 'individual_regions', file_header, folder)\n",
    "IO.save_data_to_disk(original_regions, 'original_regions', file_header, folder)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b8d8a425e81e129",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "animal_coordinates = trimmed_good_cell_trace_data['Coordinates']\n",
    "coordinate_locations, coordinate_indexes = EPM.get_coordinate_region(animal_coordinates, individual_regions)\n",
    "coordinate_pairs = list(zip(animal_coordinates, coordinate_indexes))\n",
    "distances = EPM.get_distances(individual_regions, coordinate_pairs)\n",
    "\n",
    "trimmed_good_cell_trace_data.insert(2, 'Location', coordinate_locations)\n",
    "trimmed_good_cell_trace_data.insert(3, 'Distance', distances)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1c9fd33e7518c2",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
