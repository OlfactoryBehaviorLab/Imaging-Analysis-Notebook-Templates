{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1daf917d-f5f9-42ea-baaa-08fcf28b43ce",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "# Dewan Lab Image Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1ba1747-903f-4eac-8a48-84b44728f3e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6d1aec8e-a365-49a6-b3ab-d67525a65bdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP 1A: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "48174929-fd1b-48cc-ab99-9ff1bcd9f06e",
   "metadata": {
    "tags": []
   },
   "source": [
    "import os\n",
    "os.environ['ISX'] = '0'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "from dewan_calcium.helpers import IO, parse_json\n",
    "from dewan_calcium.helpers.project_folder import ProjectFolder\n",
    "from dewan_calcium import AUROC, plotting\n",
    "\n",
    "pd.options.mode.copy_on_write = \"warn\"\n",
    "\n",
    "print('Finished importing required libraries!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d57a7bb0-be75-4f25-b35d-6732d0ea7dfa",
   "metadata": {},
   "source": [
    "### STEP 1B: User Configurables"
   ]
  },
  {
   "cell_type": "code",
   "id": "bcc7cf66ecef9dc1",
   "metadata": {},
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "pre_trial_time = 3.5  # Imaging time before the final valve opens\n",
    "post_trial_time = 3.5  # Imaging time after final valve closes\n",
    "\n",
    "# Configurables for AUROC\n",
    "baseline_duration = 2  # number of seconds before the FV turns on\n",
    "response_duration = 2  # number of seconds after the FV turns off\n",
    "plot_figures = True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2e0ce94c84e7cdf",
   "metadata": {},
   "source": [
    "# Create Project Folder to Gather and Hold all the File Paths\n",
    "\n",
    "project_folder = ProjectFolder('ODOR')\n",
    "file_header = animal + '-' + date + '-'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b898a146ab9e2431",
   "metadata": {},
   "source": [
    "# If this is the first time the project folder has been created,\n",
    "# move the files to the appropriate directories and then run this cell, otherwise skip this cell\n",
    "\n",
    "project_folder.get_data()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dc7c2ffb",
   "metadata": {},
   "source": [
    "# Get settings from imaging session and display them for the user\n",
    "\n",
    "gain, LED_power, endoscope_framerate, focal_planes = parse_json.get_session_settings(project_folder.raw_data_dir.session_json_path)\n",
    "\n",
    "print(f'Recording Gain: {gain}')\n",
    "print(f'LED Power: {LED_power}')\n",
    "print(f'Endoscope Framerate: {endoscope_framerate}')\n",
    "print(f'Focal Plane(s): {focal_planes}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "333708ce-48b1-4382-9e74-a6ae099f190c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 2: Data Import and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85f73484-fb78-4bef-8328-bd312d9abbc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2A: Import and pre-process the raw data"
   ]
  },
  {
   "cell_type": "code",
   "id": "63c403fa",
   "metadata": {},
   "source": [
    "#STEP 2A.2: LOAD INSCOPIX DATA\n",
    "\n",
    "cell_trace_data = pd.read_csv(project_folder.inscopix_dir.cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(project_folder.inscopix_dir.GPIO_path, header=0, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(project_folder.inscopix_dir.props_path, header=0, engine='pyarrow')\n",
    "odor_data = pd.read_excel(project_folder.raw_data_dir.odorlist_path, usecols=[0], header=None, engine='openpyxl') # usecols=[0] because we only care about the first column which has the odornames, row number == trial number\n",
    "cell_outlines = parse_json.get_outline_coordinates(project_folder.inscopix_dir.contours_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c95069cddb6595a4",
   "metadata": {},
   "source": [
    "# STEP 2A.2: PREPROCESSING\n",
    "\n",
    "# STEP 2A.2.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data = cell_trace_data.drop([0])\n",
    "\n",
    "# STEP 2A.2.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data = cell_trace_data.set_index(cell_trace_data.columns[0]) \n",
    "\n",
    "# STEP 2A.2.3: Remove spaces from column names and contents\n",
    "cell_trace_data.columns = cell_trace_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data.columns = GPIO_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data['ChannelName'] = GPIO_data['ChannelName'].str.replace(\" \", \"\")\n",
    "\n",
    "# STEP 2A.2.4: Reduce properties to only include the cells with only one component\n",
    "all_cell_props = all_cell_props[all_cell_props['NumComponents']==1]  # We only want cells that have one component\n",
    "all_cell_props = all_cell_props.drop(columns='Status').reset_index(drop=True)\n",
    "cell_names = all_cell_props['Name'].values\n",
    "\n",
    "# STEP 2A.2.5: PARSE GPIO DATA\n",
    "sniff_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-1\"].reset_index(drop=True)\n",
    "FV_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-2\"].reset_index(drop=True)\n",
    "\n",
    "# STEP 2A.2.6: Get a list of all the unique odors to reuse for consistency\n",
    "odor_data = pd.Series(odor_data[0], name='Odors')\n",
    "odor_list = odor_data.unique().astype(str)\n",
    "\n",
    "# OPTIONAL UNUSED DATA\n",
    "# running_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-3\"]  # Running Wheel Data\n",
    "# lick_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-4\"]  # Lick Data\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "454d5b1aa6fc53ec",
   "metadata": {},
   "source": [
    "## Run if someone forgot to put delimiters in the odor names\n",
    "\n",
    "new_odor_data = []\n",
    "\n",
    "for each in odor_data:\n",
    "    try:\n",
    "        first_val = int(each[0])\n",
    "        each = '-'.join([each[0], each[1:]])\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    new_odor_data.append(each)\n",
    "    odor_data = pd.Series(new_odor_data, name='Odors')    \n",
    "    \n",
    "odor_list = odor_data.unique().astype(str)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1bc73833cc7640d5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### STEP 2B: Manual Curation"
   ]
  },
  {
   "cell_type": "code",
   "id": "de8e82bd-0c23-432f-a462-69835dce5805",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from dewan_manual_curation import dewan_manual_curation\n",
    "\n",
    "curated_cells = dewan_manual_curation.launch_gui(project_folder_override=project_folder, cell_trace_data_override=cell_trace_data, cell_props_override=all_cell_props, cell_contours_override=cell_outlines)\n",
    "if curated_cells is None:\n",
    "    print('Error, no good cells selected!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aaa47058cc676612",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### STEP 2C: Apply Manual Curation Results and Additional Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "cbe5b11c0eab4fd1",
   "metadata": {},
   "source": [
    "# STEP 2C.1: Filter all data by the GoodCells identified in ManualCuration\n",
    "curated_cell_props = all_cell_props[all_cell_props['Name'].isin(curated_cells)].reset_index(drop=True)\n",
    "curated_trace_data = cell_trace_data[curated_cells]\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8676610888de842e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### STEP 2D: Pickle and Save all preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "id": "4022ffb995a28bb8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pickle the reorganized CellTraceData incase its needed later\n",
    "# Saves Cell Traces, GPIO, Odor List, Sniff, FV data, Good Cell Properties, Good Cells, and the labeled max projection\n",
    "# Once these have been saved, they don't need to be re-run on the same data again unless the data itself is changed\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(curated_trace_data, 'curated_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(GPIO_data, 'GPIO_data', file_header, folder)\n",
    "IO.save_data_to_disk(odor_data, 'odor_data', file_header, folder)\n",
    "IO.save_data_to_disk(odor_list, 'odor_list', file_header, folder)\n",
    "IO.save_data_to_disk(FV_data, 'FV_data', file_header, folder)\n",
    "IO.save_data_to_disk(curated_cell_props, 'curated_cell_props', file_header, folder)\n",
    "IO.save_data_to_disk(sniff_data, 'sniff_table', file_header, folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ba952d5-9392-413e-bf3a-49086c6a583f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Checkpoint 1: Load Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "0e1a40e5-f3cc-432c-a415-0dbc157caa00",
   "metadata": {},
   "source": [
    "# Opens the saved pickle files.  If the files have already been saved, code can be re-run\n",
    "# starting from this point\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "curated_trace_data = IO.load_data_from_disk('curated_trace_data', file_header, folder)\n",
    "GPIO_data = IO.load_data_from_disk('GPIO_data', file_header, folder)\n",
    "odor_data = IO.load_data_from_disk('odor_data', file_header, folder)\n",
    "odor_list = IO.load_data_from_disk('odor_list', file_header, folder)\n",
    "FV_data = IO.load_data_from_disk('FV_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "sniff_data = IO.load_data_from_disk('sniff_table', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']  # List of cells, referenced periodically"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "945f4f52",
   "metadata": {},
   "source": [
    "## STEP 3: Indexing and Aligning FV/Sniff/CellTrace Data"
   ]
  },
  {
   "cell_type": "code",
   "id": "c5d247244009e2d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# STEP 3A: Parses the final valve data to identify when the final valve is open vs when it is closed based on TTL pulse from Arduino.\n",
    "FV_values = FV_data['Value'].astype(float).values # Get FV Values\n",
    "num_values = len(FV_values)\n",
    "valve_status = 0\n",
    "FV_on_indexes = []\n",
    "FV_off_indexes = []\n",
    "for i in trange((num_values - 1), desc=\"Processing: \"):\n",
    "    valve_val_diff = FV_values[i + 1] - FV_values[i]\n",
    "\n",
    "    if valve_status == 0:    # Start with valve off\n",
    "        if valve_val_diff > 10000: # If the difference is a very large positive number, the valve opened\n",
    "            FV_on_indexes.append(i + 1)\n",
    "            valve_status = 1 # Set valve state to open\n",
    "    else:\n",
    "        if valve_val_diff < -10000: # If the difference is a very laarge negative number, the valve closed\n",
    "            FV_off_indexes.append(i)\n",
    "            valve_status = 0 # Set valve state to closed\n",
    "\n",
    "FV_indexes = pd.DataFrame(zip(FV_on_indexes, FV_off_indexes), columns=['On', 'Off'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "be0f958d28b3b38c",
   "metadata": {},
   "source": [
    "# STEP 3B.1: Find trial start and end times with the pre/post trial offsets\n",
    "time_points = FV_data['Time(s)']\n",
    "\n",
    "FV_on_times = time_points.iloc[FV_indexes['On']].astype(float)\n",
    "FV_off_times = time_points.iloc[FV_indexes['Off']].astype(float)\n",
    "\n",
    "trial_start_times = FV_on_times.subtract(pre_trial_time)\n",
    "trial_end_times = FV_off_times.add(post_trial_time)\n",
    "FV_times = pd.DataFrame(zip(FV_on_times, FV_off_times), columns=['On', 'Off'])\n",
    "trial_times = pd.DataFrame(zip(trial_start_times, trial_end_times), columns=['Start', 'End'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "54b1491d8210ffa4",
   "metadata": {},
   "source": [
    "# STEP 3B.2: Find the start/end indexes for the CellTrace data based on the closest time points for each trial\n",
    "# NOTE: Needed because the sample rate of the GPIO and the Endoscope are different, so the time points do not always perfectly line up\n",
    "# Occasionally, you will get trials that are 1 frame/sample longer/shorter than each other due to this mismatch\n",
    "cell_trace_start_indices = []\n",
    "cell_trace_stop_indices = []\n",
    "\n",
    "time_points = curated_trace_data.index.values\n",
    "\n",
    "for i, each in enumerate(tqdm(trial_times['Start'], desc=\"Trial: \")):\n",
    "    if time_points[-1] < trial_times['End'].iloc[-1] and i == len(trial_times['Start'])-1:\n",
    "        # This is an edge case for when the last trial got cut off early or the experiment crashed\n",
    "        # It checks to see if the EndTime occurred after the last available time point\n",
    "        continue\n",
    "        \n",
    "    cell_trace_start_indices.append(np.where(time_points <= each)[0][-1]) # Find first value less than/= the start time. We would always rather start 1 frame early than late\n",
    "    cell_trace_stop_indices.append(np.where(time_points >= trial_times['End'].iloc[i])[0][0]) # Find the first value greater than/= the end time. We would always rather stop 1 frame late than early\n",
    "\n",
    "cell_trace_indices = pd.DataFrame(zip(cell_trace_start_indices, cell_trace_stop_indices), columns = ['Start', 'Stop'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "638e14c99453ed71",
   "metadata": {},
   "source": [
    "# # STEP 3C: Find the start/end indexes for the SNIFF data based on the closest time points for each trial\n",
    "# # Compiles data for sniffing from good trials\n",
    "# sniff_start_indices = []\n",
    "# sniff_end_indices = []\n",
    "#\n",
    "# time_points = sniff_data['Time(s)']\n",
    "#\n",
    "# for i in trange(len(trial_times), desc=\"Sniff Trial: \"):\n",
    "#     if time_points.iloc[-1] < trial_times['End'].iloc[-1] and i == len(trial_times['Start'])-1:\n",
    "#         # This is an edge case for when the last trial got cut off early or the experiment crashed\n",
    "#         # It checks to see if the EndTime occurred after the last available time point\n",
    "#         continue\n",
    "#     sniff_start_indices.append(np.where(time_points <= trial_times['Start'].iloc[i])[0][-1]) # Find first index less than/= the start time. We would always rather start 1 frame early than late\n",
    "#     sniff_end_indices.append(np.where(time_points >= trial_times['End'].iloc[i])[0][0]) # Find the first index greater than/= the end time. We would always rather stop 1 frame late than early\n",
    "#\n",
    "# sniff_indices = pd.DataFrame(zip(sniff_start_indices, sniff_end_indices), columns=['Start', 'End'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4bf4423f4b9a6a81",
   "metadata": {},
   "source": [
    "# STEP 3D: TRIM ODOR LIST\n",
    "num_trials = len(FV_indexes)\n",
    "odor_data = odor_data.iloc[:num_trials] # If any trials on the end are cut off, we need to trim them from the list\n",
    "\n",
    "# TODO: STEP 3E: SAVE SNIFF DATA INTO SEPARATE FILE, CURRENTLY BROKEN, DON'T USE"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ff6cfc3-3ede-47d2-a77f-5ef5bf1e6d66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## STEP 4: Gather all cell v. time v. trial data into single array"
   ]
  },
  {
   "cell_type": "code",
   "id": "4ca52c9c0ce37b58",
   "metadata": {},
   "source": [
    "# STEP 4A: COMBINE ALL OF THE CELL TRACE DATA INTO A CELL X TRIAL X FRAMES ARRAY\n",
    "combined_data = []\n",
    "num_cells = len(cell_names)\n",
    "odor_labels = odor_data.astype(str)  # All the odors as strings\n",
    "for cell in tqdm(cell_names, desc=\"Cell: \"): # Loop through each cell\n",
    "    cell_data = []\n",
    "\n",
    "    for indices in cell_trace_indices[['Start', 'Stop']].values: # Loop through trials\n",
    "        start_index, stop_index = indices\n",
    "        trial_data = curated_trace_data[cell].iloc[start_index:stop_index].reset_index(drop=True)\n",
    "        cell_data.append(trial_data)\n",
    "    cell_data = pd.DataFrame(cell_data, index=odor_labels).T  # Transpose dataframe so columns are trials and rows are frames\n",
    "    cell_data = cell_data.reset_index(drop=True)\n",
    "    combined_data.append(cell_data)\n",
    "\n",
    "# STEP 4B: CROP THE ARRAY TO THE SHORTEST TRIAL TO GET RID OF TRAILING ZEROS\n",
    "combined_data = pd.concat(combined_data, axis=1, keys=cell_names, names=['Cells', 'Frames'])\n",
    "combined_data = combined_data.dropna(axis=0)\n",
    "\n",
    "# STEP 4C: BASELINE SHIFT THE DATA SO THERE ARE NO NEGATIVE NUMBERS\n",
    "min_value = abs(combined_data.min().min()) # Get minimum for each row, then the minimum of those values\n",
    "combined_data_shift = combined_data.add(min_value)\n",
    "\n",
    "# STEP 4D: GET TIMESTAMPS FOR EACH TRIAL\n",
    "# Note: There are two lists of timestamps.\n",
    "# List 1) FinalValveTimeMap ranges from preTrialTime -> Final Valve On Time -> postTrialTime then the Final Valve On Time is subtracted from the whole list to set the FVOnTime to zero (e.g -3.5 -> 0 -> 3.5)\n",
    "# List 2) All the raw time values in Unix Time Form (Inscopix time output)\n",
    "\n",
    "FV_timestamps = []\n",
    "unix_timestamps = []\n",
    "\n",
    "trace_times = curated_trace_data.index.values\n",
    "\n",
    "for trial in trange(num_trials, desc=\"Trial: \"): # Loop through each trial\n",
    "    start_index, end_index = cell_trace_indices.iloc[trial]\n",
    "    timestamps = trace_times[start_index:end_index].astype(float)\n",
    "\n",
    "    zero_time = FV_times['On'].iloc[trial]\n",
    "    FV_time = timestamps - zero_time\n",
    "    FV_timestamps.append(FV_time)\n",
    "    unix_timestamps.append(timestamps)\n",
    "    \n",
    "FV_timestamps = pd.DataFrame(FV_timestamps)\n",
    "unix_timestamps = pd.DataFrame(unix_timestamps)\n",
    "\n",
    "# STEP 4E: CROP THE ARRAYs TO THE SHORTEST TRIAL TO GET RID OF TRAILING ZEROS\n",
    "FV_timestamps = FV_timestamps.dropna(axis=1)\n",
    "unix_timestamps = unix_timestamps.dropna(axis=1)\n",
    "\n",
    "# STEP 5E: Transpose and add odor names\n",
    "FV_timestamps = FV_timestamps.T\n",
    "FV_timestamps.columns = odor_labels\n",
    "unix_timestamps = unix_timestamps.T\n",
    "unix_timestamps.columns = odor_labels"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b87d73f861d55020",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## STEP 5: SAVE THE COMBINED DATA\n",
    "##### The combined data file contains a Table of Contents with the contour information for each cell, a TimeStamp map (rows -> trial; columns -> frames), and then a tab for each cell with the rows labeled with the odor for that particular trial, and columns are frames."
   ]
  },
  {
   "cell_type": "code",
   "id": "216dbef78f303fc6",
   "metadata": {},
   "source": [
    "# STEP 5A: CREATE TABLE OF CONTENTS FOR CELL DESCRIPTORS\n",
    "column_names = ['Name', 'CentroidX', 'CentroidY', 'NumComponents', 'Size']\n",
    "toc = curated_cell_props[column_names]\n",
    "toc = toc.set_index('Name', drop=True)\n",
    "\n",
    "# STEP 5B: SET FILE PATH AND CREATE EXCEL-SHEET WRITER\n",
    "file_name = f'{file_header}CombinedData.xlsx'\n",
    "path = project_folder.analysis_dir.combined_dir.path.joinpath(file_name)\n",
    "writer = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "\n",
    "# STEP 5C: WRITE TABLE OF CONTENTS\n",
    "toc.to_excel(writer, sheet_name='TOC')\n",
    "# STEP 5D: WRITE FINAL VALVE TIME MAP FOR ALL TRIALS\n",
    "time_columns = np.arange(FV_timestamps.shape[1]) # Columns are 0 -> number of frames/trial\n",
    "time_indexes = np.arange(1, FV_timestamps.shape[0] + 1) # Rows are 1 -> number of trials\n",
    "time_map_sheet = pd.DataFrame(FV_timestamps)\n",
    "time_map_sheet.to_excel(writer, sheet_name='TimeMap')\n",
    "# STEP 5E: WRITE ALL CELL TRACE DATA\n",
    "for cell in tqdm(cell_names, desc=\"Writing Cell: \"):\n",
    "    _data = combined_data_shift[cell]\n",
    "    _data.to_excel(writer, sheet_name=f'Cell {cell}')\n",
    "\n",
    "writer.close()\n",
    "\n",
    "# STEP 5F: ORGANIZE AND WRITE SNIFF DATA TO FILE TODO: Keep or discard?\n",
    "# headers = []\n",
    "# for i in range(len(SniffData[0,:])):\n",
    "#     headers.append('Trial ' + str(i))\n",
    "#     SniffDF = pd.DataFrame(SniffData)\n",
    "#     sniff_path = f'./CombinedData/{file_header}/SniffData.xlsx'\n",
    "#     SniffDF.to_excel(sniff_path, sheet_name = 'Data', header=headers)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "875be4dfc910f64",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### STEP 5H: Save information needed for AUROC\n",
    "##### The combined data excel sheet is saved to __./ImagingAnalysis/CombinedData/__\n",
    "##### Any data needed for the AUROC analysis that has not been saved will be saved in __./ImagingAnalysis/AUROCImports__"
   ]
  },
  {
   "cell_type": "code",
   "id": "d191fea68a3354a4",
   "metadata": {},
   "source": [
    "folder = project_folder.analysis_dir.combined_dir.path\n",
    "IO.save_data_to_disk(combined_data, 'combined_data', file_header, folder)\n",
    "IO.save_data_to_disk(combined_data_shift, 'combined_data_shift', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "IO.save_data_to_disk(FV_indexes, 'FV_indexes', file_header, folder)\n",
    "IO.save_data_to_disk(unix_timestamps, 'unix_timestamps', file_header, folder)\n",
    "IO.save_data_to_disk(FV_timestamps, 'FV_timestamps', file_header, folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5785a0e7-4c69-41a6-94f5-7f82b4373234",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Checkpoint 2: Load Data for AUROC"
   ]
  },
  {
   "cell_type": "code",
   "id": "f51f5276-994e-440c-96fe-93b04ff0c21d",
   "metadata": {},
   "source": [
    "folder = project_folder.analysis_dir.combined_dir.path\n",
    "combined_data_shift = IO.load_data_from_disk('combined_data_shift', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "FV_data = IO.load_data_from_disk('FV_data', file_header, folder)\n",
    "FV_indexes =  IO.load_data_from_disk('FV_indexes', file_header, folder)\n",
    "unix_timestamps = IO.load_data_from_disk('unix_timestamps', file_header, folder)\n",
    "FV_timestamps = IO.load_data_from_disk('FV_timestamps', file_header, folder)\n",
    "odor_data = IO.load_data_from_disk('odor_data', file_header, folder)\n",
    "odor_list = IO.load_data_from_disk('odor_list', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e453f7ece5780b7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## STEP 6: AUROC\n",
    "### STEP 6A: RUN AUROC"
   ]
  },
  {
   "cell_type": "code",
   "id": "ee09afdff36a45a0",
   "metadata": {},
   "source": [
    "# STEP 6A.1: RUN AUROC FOR ON-TIME CELLS\n",
    "# Note: On time cells are those that respond during the stimulus window (0s-2s)\n",
    "on_time_AUROC_return = AUROC.pooled_odor_auroc(combined_data_shift, FV_timestamps, baseline_duration, 8, False) # This takes a long time!\n",
    "# # STEP 6A.2: RUN AUROC FOR LATENT CELLS\n",
    "# Note: Latent cells are those that respond immediately after the stimulus window (2s-4s)\n",
    "latent_AUROC_return = AUROC.pooled_odor_auroc(combined_data_shift, FV_timestamps, baseline_duration, 8, True) # This takes a long time!\n",
    "\n",
    "### STEP 6B: PARSE AUROC OUTPUT\n",
    "ontime_dataframes = [pd.DataFrame(return_dict).set_index(odor_list) for return_dict in on_time_AUROC_return]\n",
    "ontime_AUROC_data = pd.concat(ontime_dataframes, axis = 1, keys=cell_names)\n",
    "\n",
    "latent_dataframes = [pd.DataFrame(return_dict).set_index(odor_list) for return_dict in latent_AUROC_return]\n",
    "latent_AUROC_data = pd.concat(latent_dataframes, axis = 1, keys=cell_names)\n",
    "significance_table = pd.DataFrame()\n",
    "\n",
    "on_time = []\n",
    "latent = []\n",
    "\n",
    "for cell in cell_names:\n",
    "    ontime_significance_data = ontime_AUROC_data[cell]['significance_chart']\n",
    "    latent_significance_data = latent_AUROC_data[cell]['significance_chart'].copy()\n",
    "\n",
    "    latent_significance_data.loc[latent_significance_data == 1] = 3\n",
    "    latent_significance_data.loc[latent_significance_data == 2] = 4\n",
    "    on_time.append(ontime_significance_data)\n",
    "    latent.append(latent_significance_data)\n",
    "    significance_data = ontime_significance_data.copy()\n",
    "    zero_mask = ontime_significance_data == 0  # We are only interested in updating values that are zero\n",
    "    significance_data.loc[zero_mask] = latent_significance_data.loc[zero_mask]  # Update zero values only\n",
    "    significance_table = pd.concat([significance_table, significance_data], axis=1)\n",
    "\n",
    "significance_table.columns=cell_names\n",
    "\n",
    "### STEP 6C: Save AUROC Output\n",
    "# STEP 6C.1: SAVE SIGNIFICANCE TABLE TO XLSX\n",
    "folder = project_folder.analysis_dir.output_dir.path\n",
    "\n",
    "significance_table_file_name = f'{file_header}SignificanceTable.xlsx'\n",
    "significance_file_path = folder.joinpath(significance_table_file_name)\n",
    "significance_table.to_excel(significance_file_path)\n",
    "# \n",
    "# ontime_file_name = f'{file_header}ontime_significance_table.xlsx'\n",
    "# ontime_file_path = folder.joinpath(ontime_file_name)\n",
    "# ontime_significance_table.to_excel(ontime_file_path)\n",
    "# \n",
    "# latent_file_name = f'{file_header}latent_significance_table.xlsx'\n",
    "# latent_file_path = folder.joinpath(latent_file_name)\n",
    "# latent_significance_table.to_excel(latent_file_path)\n",
    "\n",
    "# STEP 6C.2: PICKLE DATA\n",
    "IO.save_data_to_disk(ontime_AUROC_data, 'ontime_AUROC_data', file_header, folder)\n",
    "# IO.save_data_to_disk(ontime_significance_table, 'ontime_significance_table', file_header, folder)\n",
    "IO.save_data_to_disk(latent_AUROC_data, 'latent_AUROC_data', file_header, folder)\n",
    "# IO.save_data_to_disk(latent_significance_table, 'latent_significance_table', file_header, folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afb6f565",
   "metadata": {},
   "source": [
    "### Checkpoint 3: Load Data for Plotting"
   ]
  },
  {
   "cell_type": "code",
   "id": "581d2227-89b4-44cb-8eef-2360b42c869c",
   "metadata": {},
   "source": [
    "folder = project_folder.analysis_dir.output_dir.path\n",
    "\n",
    "ontime_AUROC_data = IO.load_data_from_disk('ontime_AUROC_data', file_header, folder)\n",
    "latent_AUROC_data = IO.load_data_from_disk('latent_AUROC_data', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.combined_dir.path\n",
    "combined_data_shift = IO.load_data_from_disk('combined_data_shift', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "odor_list = IO.load_data_from_disk('odor_list', file_header, folder)\n",
    "FV_timestamps = IO.load_data_from_disk('FV_timestamps', file_header, folder)\n",
    "odor_data = IO.load_data_from_disk('odor_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "60179e8ae9dc5576",
   "metadata": {},
   "source": [
    "## STEP 7: Plotting"
   ]
  },
  {
   "cell_type": "code",
   "id": "d5a7517001c8ccf5",
   "metadata": {},
   "source": [
    "# STEP 7A: Plot AUROC Distributions (Optional)\n",
    "plotting.pooled_auroc_distributions(ontime_AUROC_data, cell_names, odor_data, project_folder)\n",
    "plotting.pooled_auroc_distributions(latent_AUROC_data, cell_names, odor_data, project_folder, True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d3396574d5926a8d",
   "metadata": {},
   "source": [
    "# STEP 7B: Plot Significant Cell Traces\n",
    "# Plot significant cells v odors\n",
    "# Note: three optional arguments 1) latent 2) all_cells, 3) num_workers\n",
    "# 1) and 2) are False by default and 3) is None; example lines for plotting all cells are included below\n",
    "# Broken as of 11/3/2024; need to refactor to take in the new combined significance table; focusing on SVM for now though!\n",
    "# plotting.pooled_cell_plotting(combined_data_shift, ontime_AUROC_data, ontime_significance_table, FV_timestamps, cell_names, odor_list, response_duration, project_folder, False, False)\n",
    "# \n",
    "# plotting.pooled_cell_plotting(combined_data_shift, latent_AUROC_data, latent_significance_table, FV_timestamps, cell_names, odor_list, response_duration, project_folder, True, False)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImagingAnalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "977baf04aa409d7582f6e94b1f1f1d2e9ac45da44046a9cec7b1a770a676514b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
