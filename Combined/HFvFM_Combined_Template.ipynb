{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dewan Lab EPM Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1471a0c2b0c3e8ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5d20e6bdd90448"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "8977fe958ff15eda",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['ISX'] = '0'  # Set to zero so we don't try to load the isx module\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# TODO: Figure out OASIS numpy complaint\n",
    "from dewan_calcium import AUROC, plotting, deconv\n",
    "from dewan_calcium.helpers import IO, parse_json, HFvFM\n",
    "from dewan_calcium.helpers.project_folder import ProjectFolder\n",
    "\n",
    "print(\"Importing required packages complete!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1B: User Configurables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbadb82b6bdf09c"
  },
  {
   "cell_type": "code",
   "source": [
    "animal = 'Combined_HFvFM'\n",
    "date = '10-24-2024'\n",
    "\n",
    "HF_first = True\n",
    "TRIAL_DURATION_S = 300\n",
    "PSEUDOTRIAL_LEN_S = 2  # \n",
    "AUROC_NUM_PSEUDOTRIALS = 20\n",
    "ENDOSCOPE_FRAMERATE = 10\n",
    "\n",
    "DECAY_TIME_S = 0.4  # Time in seconds for the decay of 10 action potentials (0.4 for GCaMP6f)\n",
    "RISE_TIME_S = 0.08  # Time in seconds for the rise to peak of 10 action potentials (0.08 for GCaMP6f)\n",
    "INTER_SPIKE_INTERVAL_S = 0.1 # Time in seconds that must elapse before another \"spike\"\n",
    "PEAK_MIN_DUR_S = 0.4  # Time in seconds that must elapse for a \"peak\" to be considered a \"spike\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17c61cc38601c39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### STEP 1C: Load Project Folder"
   ],
   "id": "743384ae8afd7f4a"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Project Folder to Gather and Hold all the File Paths\n",
    "project_folder = ProjectFolder('HFvFM', combined=True, project_dir=r'C:\\Projects\\Test_Data\\4_Combined\\HFvFM')\n",
    "file_header = animal + '-' + date + '-'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b153d57361969394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If this is the first time the project folder has been created, move the files to the appropriate directories and then run this cell, otherwise skip this cell\n",
    "project_folder.get_data()"
   ],
   "id": "8335d89603fe71ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_data = pd.read_pickle(project_folder.raw_data_dir.combined_data_path, compression={'method': 'xz'})\n",
    "cell_names = combined_data.columns.get_level_values(0).values\n",
    "trial_labels = np.unique(combined_data.columns.get_level_values(1).values)\n",
    "#trial_labels = IO.load_data_from_disk('trial_labels', file_header, folder)\n",
    "#cell_names = curated_cell_props['Name']"
   ],
   "id": "dc876c81d6ffe3a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "60f1e02008e55284"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6A: Smooth raw df/F values with OASIS\n",
    "smoothing_kernel = deconv.calc_smoothing_params(ENDOSCOPE_FRAMERATE, DECAY_TIME_S, RISE_TIME_S)\n",
    "smoothed_trace_data = deconv.pooled_deconvolution(combined_data, smoothing_kernel, workers=20)"
   ],
   "id": "b4f10fec385974cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6B: Identify transients\n",
    "z_scored_data = deconv.z_score_data(smoothed_trace_data, cell_names)\n",
    "transient_indexes = deconv.find_peaks(z_scored_data, cell_names, ENDOSCOPE_FRAMERATE, INTER_SPIKE_INTERVAL_S, PEAK_MIN_DUR_S, )"
   ],
   "id": "a51a7eabb2b82a12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "IO.save_data_to_disk(smoothed_trace_data, 'combined_smoothed_data', file_header, project_folder.analysis_dir.output_dir.path)",
   "id": "43cd33a9615c5e06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6C: Get Stats for Each Cell\n",
    "for cell in cell_names:\n",
    "    cell_data = transient_indexes[cell]\n",
    "    \n",
    "    stats = HFvFM.calc_transient_stats(cell_data, trial_labels)\n",
    "    \n",
    "    cell_data['stats'] = stats\n",
    "    transient_indexes[cell] = cell_data"
   ],
   "id": "cd6e2ca82694f11e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEPS 6D: Stack Trials from each Cell\n",
    "stacked_indices = HFvFM.stack_trial_indices(trial_labels, cell_names, transient_indexes)"
   ],
   "id": "cf12a83b24f7231f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6E: Offset each trial to match its trial\n",
    "from functools import partial\n",
    "\n",
    "trial_length_frames = ENDOSCOPE_FRAMERATE * TRIAL_DURATION_S\n",
    "\n",
    "for i, trial in enumerate(trial_labels):\n",
    "    if i > 0:\n",
    "        offset_value = i * trial_length_frames  # Max trial length\n",
    "        print(f'{trial}: {offset_value}')\n",
    "        \n",
    "        temp_func = partial(HFvFM.add_if_num, i*offset_value)\n",
    "        trial_dataframe = stacked_indices[trial]\n",
    "        stacked_indices[trial] = trial_dataframe.map(temp_func)\n",
    "        \n",
    "    stacked_indices[trial] = stacked_indices[trial].T\n",
    "    stacked_indices[trial].index=cell_names"
   ],
   "id": "4ecc9683239fb25a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6F: Combine Stats into a DataFrame\n",
    "cell_stats = {}\n",
    "for cell in cell_names:\n",
    "    cell_stats[cell] = transient_indexes[cell]['stats']  \n",
    "cell_stats = pd.DataFrame(cell_stats).T"
   ],
   "id": "7bdc1b250d053642",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6G: Combine Stats, Transients, and Remove Spaces\n",
    "\n",
    "super_mega_ultra_df = pd.DataFrame()\n",
    "for trial in trial_labels: \n",
    "    trial_df = stacked_indices[trial]\n",
    "    num_columns = len(trial_df.columns)\n",
    "    new_columns = [trial for _ in range(num_columns)]\n",
    "    trial_df.columns = new_columns\n",
    "    super_mega_ultra_df = pd.concat([super_mega_ultra_df, trial_df], axis=1)\n",
    "    \n",
    "super_mega_ultra_df = super_mega_ultra_df.apply(lambda row: pd.Series(row.dropna().values), axis=1)  # Voodoo to remove NaN values\n",
    "super_mega_ultra_df = pd.concat((cell_stats, super_mega_ultra_df), axis=1)\n",
    "\n",
    "file_name = f'{file_header}TransientLocations.xlsx'\n",
    "path = project_folder.analysis_dir.output_dir.path.joinpath(file_name)\n",
    "\n",
    "super_mega_ultra_df.to_excel(path)"
   ],
   "id": "e34715639f700d00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6H: Save deconv data\n",
    "folder = project_folder.analysis_dir.output_dir.subdir('deconv')\n",
    "\n",
    "IO.save_data_to_disk(smoothed_trace_data, 'smoothed_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(z_scored_data, 'z_scored_data', file_header, folder)\n",
    "IO.save_data_to_disk(transient_indexes, 'transient_indexes', file_header, folder)"
   ],
   "id": "11e121f724e3418",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checkpoint 3",
   "id": "12ee5b1d2df6700c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "trial_labels = IO.load_data_from_disk('trial_labels', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']\n",
    "\n",
    "folder = project_folder.analysis_dir.combined_dir.path\n",
    "combined_data = IO.load_data_from_disk('combined_data', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.output_dir.subdir('deconv')\n",
    "smoothed_trace_data = IO.load_data_from_disk('smoothed_trace_data', file_header, folder)\n",
    "z_scored_data = IO.load_data_from_disk('z_scored_data', file_header, folder)\n",
    "transient_indexes = IO.load_data_from_disk('transient_indexes', file_header, folder)"
   ],
   "id": "501038e47fa09952",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7: Pseudotrial creation and auROC Analysis",
   "id": "995c8550f343c6bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 7A: BASELINE SHIFT THE DATA SO THERE ARE NO NEGATIVE NUMBERS\n",
    "min_value = abs(combined_data.min().min()) # Get minimum for each row, then the minimum of those values\n",
    "combined_data_shift = combined_data.add(min_value)"
   ],
   "id": "6c0ff04157cf10ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 7B: Get Pseudotrials and stack the data\n",
    "pseudotrial_dff_per_cell = HFvFM.get_dff_for_pseudotrials(combined_data_shift, cell_names, trial_labels, PSEUDOTRIAL_LEN_S, ENDOSCOPE_FRAMERATE)\n",
    "stacked_pseudotrials = HFvFM.stack_trial_indices(trial_labels, cell_names, pseudotrial_dff_per_cell)"
   ],
   "id": "1541fe7b555cfc7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 7C: Get mean dF/F value for each trial\n",
    "pseudotrial_means = {}\n",
    "\n",
    "for trial in trial_labels:\n",
    "    trial_data = stacked_pseudotrials[trial].T\n",
    "    trial_means = trial_data.map(np.mean)\n",
    "    trial_means.index = cell_names\n",
    "    pseudotrial_means[trial] = trial_means"
   ],
   "id": "57ee6d0338be0da3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 7D: Run auROC on below groups and save data\n",
    "groups = [['HF-1', 'HF-2'], ['FM-1', 'FM-2']]\n",
    "auroc_returns = AUROC.pooled_HFFM_auroc(pseudotrial_means, groups, num_workers=20)\n",
    "\n",
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "IO.save_data_to_disk(auroc_returns, 'auroc_returns', file_header, folder)"
   ],
   "id": "b476de461314da78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CHECKPOINT 4",
   "id": "f905ce5c0f15644d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "auroc_returns = IO.load_data_from_disk('auroc_returns', file_header, folder)"
   ],
   "id": "d419233581d9c635",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 8: Create figures and save data",
   "id": "83f2e8edeec75c54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 8A: Plot auROC Figures\n",
    "plotting.plot_auroc_distribution(auroc_returns, project_folder)\n",
    "plotting.plot_auroc_shuffles(auroc_returns, project_folder)"
   ],
   "id": "dc52eefb336b94cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## STEP 8B: Restructure returned items into a dataframe and save\n",
    "auroc_return_dict = {}\n",
    "\n",
    "for cell_data in auroc_returns:\n",
    "    cell_name = cell_data['name']\n",
    "    cell_data.pop('name', None)\n",
    "    \n",
    "    auroc_val = round(cell_data['auroc'], 3)\n",
    "    direction_index = round(2 * (auroc_val - 0.5), 2)\n",
    "    \n",
    "    cell_data['auroc'] = auroc_val\n",
    "    cell_data['direction_index'] = direction_index\n",
    "    \n",
    "    auroc_return_dict[cell_name] = cell_data\n",
    "    \n",
    "HFvFM_df = pd.DataFrame(auroc_return_dict).T\n",
    "folder = project_folder.analysis_dir.output_dir.path\n",
    "file_name = f'{file_header}HFvFM_data_output.xlsx'\n",
    "file_path = folder.joinpath(file_name)\n",
    "HFvFM_df.to_excel(file_path)"
   ],
   "id": "b89a2455fd6158da",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
