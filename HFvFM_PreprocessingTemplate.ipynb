{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Dewan Lab EPM Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1471a0c2b0c3e8ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5d20e6bdd90448"
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['ISX'] = '0'  # Set to zero so we don't try to load the isx module\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from dewan_calcium import deconv, AUROC, plotting  # Need to have the rebuilt version of OASIS installed\n",
    "from dewan_calcium.helpers import IO, parse_json, HFvFM\n",
    "from dewan_calcium.helpers.project_folder import ProjectFolder\n",
    "\n",
    "print(\"Importing required packages complete!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1B: User Configurables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbadb82b6bdf09c"
  },
  {
   "cell_type": "code",
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "HF_first = True\n",
    "TRIAL_DURATION_S = 300\n",
    "PSEUDOTRIAL_LEN_S = 2  # \n",
    "AUROC_NUM_PSEUDOTRIALS = 20\n",
    "\n",
    "DECAY_TIME_S = 0.4  # Time in seconds for the decay of 10 action potentials (0.4 for GCaMP6f)\n",
    "RISE_TIME_S = 0.08  # Time in seconds for the rise to peak of 10 action potentials (0.08 for GCaMP6f)\n",
    "INTER_SPIKE_INTERVAL_S = 0.1 # Time in seconds that must elapse before another \"spike\"\n",
    "PEAK_MIN_DUR_S = 0.4  # Time in seconds that must elapse for a \"peak\" to be considered a \"spike\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17c61cc38601c39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### STEP 1C: Load Project Folder"
   ],
   "id": "743384ae8afd7f4a"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Project Folder to Gather and Hold all the File Paths\n",
    "project_folder = ProjectFolder('HFvFM', project_dir='/mnt/r2d2/2_Inscopix/1_DTT/2_HFvFM/VGLUT/VGLUT-23')\n",
    "file_header = animal + '-' + date + '-'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b153d57361969394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If this is the first time the project folder has been created, move the files to the appropriate directories and then run this cell, otherwise skip this cell\n",
    "project_folder.get_data()"
   ],
   "id": "8335d89603fe71ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get settings from imaging session and display them for the user\n",
    "\n",
    "gain, LED_power, ENDOSCOPE_FRAMERATE, focal_planes = parse_json.get_session_settings(project_folder.raw_data_dir.session_json_path)\n",
    "\n",
    "print(f'Endoscope Acquisition Framerate: {ENDOSCOPE_FRAMERATE}')\n",
    "print(f'Recording Gain: {gain}')\n",
    "print(f'LED Power: {LED_power}')\n",
    "print(f'Focal Plane(s): {focal_planes}')"
   ],
   "id": "4181d09c235c41ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2A: Import and pre-process the raw data"
   ],
   "id": "b8e0375d9126c67a"
  },
  {
   "cell_type": "code",
   "source": [
    "#STEP 2A.1: LOAD INSCOPIX DATA\n",
    "\n",
    "cell_trace_data = pd.read_csv(project_folder.inscopix_dir.cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(project_folder.inscopix_dir.GPIO_path, header=0, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(project_folder.inscopix_dir.props_path, header=0, engine='pyarrow')\n",
    "cell_outlines = parse_json.get_outline_coordinates(project_folder.inscopix_dir.contours_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abd14e642db457ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2A.2: PREPROCESSING\n",
    "\n",
    "# STEP 2A.2.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data = cell_trace_data.drop([0])\n",
    "\n",
    "# STEP 2A.2.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data = cell_trace_data.set_index(cell_trace_data.columns[0]) \n",
    "\n",
    "# STEP 2A.2.3: Remove spaces from column names and contents\n",
    "cell_trace_data.columns = cell_trace_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data.columns = GPIO_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data['ChannelName'] = GPIO_data['ChannelName'].str.replace(\" \", \"\")\n",
    "\n",
    "# STEP 2A.2.4: Reduce properties to only include the cells with only one component\n",
    "all_cell_props = all_cell_props[all_cell_props['NumComponents']==1]  # We only want cells that have one component\n",
    "all_cell_props = all_cell_props.drop(columns='Status').reset_index(drop=True)\n",
    "cell_names = all_cell_props['Name'].values\n",
    "\n",
    "# STEP 2A.2.5: PARSE GPIO DATA\n",
    "sniff_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-1\"].reset_index(drop=True)\n",
    "FV_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-2\"].reset_index(drop=True)\n",
    "\n",
    "# OPTIONAL UNUSED DATA\n",
    "# running_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-3\"]  # Running Wheel Data\n",
    "# lick_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-4\"]  # Lick Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c367711c48588a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### STEP 2B: Manual Curation -- Must be run in PyCharm or VS Code",
   "metadata": {
    "collapsed": false
   },
   "id": "e21d1f96278b274b"
  },
  {
   "cell_type": "code",
   "source": [
    "## STEP 2B.1 Run Manual Curation GUI\n",
    "from dewan_manual_curation import manual_curation\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cells = manual_curation.launch_gui(project_folder_override=project_folder, cell_trace_data_override=cell_trace_data, cell_props_override=all_cell_props, cell_contours_override=cell_outlines)\n",
    "pd.Series(curated_cells).to_csv(folder.joinpath('cell_names.csv'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d6c2c8fc4f07b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "markdown",
   "source": "### (Alternate) STEP 2B: Manual Curation -- Load previous manual curation result",
   "id": "19da5d5174f45e69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## STEP 2B.2 (OPTIONAL): Load previous manual curation results incase we need to reload the raw data\n",
    "curated_cells = pd.read_csv(project_folder.analysis_dir.preprocess_dir.joinpath('cell_names.csv'), index_col=[0]).values.tolist()\n",
    "curated_cells = [cell[0] for cell in curated_cells]"
   ],
   "id": "3ba8f25e9d1881b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2C: Apply Manual Curation Results and Additional Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba514ce06958860"
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2C.1: Filter all data by the GoodCells identified in ManualCuration\n",
    "\n",
    "curated_cell_props = all_cell_props[all_cell_props['Name'].isin(curated_cells)].reset_index(drop=True)\n",
    "curated_trace_data = cell_trace_data[curated_cells]\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d4ee4dc735b1d81",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2D: Pickle and Save all preprocessed data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bec801c85b27c1bb"
  },
  {
   "cell_type": "code",
   "source": [
    "# Pickle the reorganized CellTraceData incase its needed later\n",
    "# Saves Cell Traces, GPIO, Odor List, Sniff, FV data, Good Cell Properties, Good Cells, and the labeled max projection\n",
    "# Once these have been saved, they don't need to be re-run on the same data again unless the data itself is changed\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(curated_trace_data, 'curated_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(GPIO_data, 'GPIO_data', file_header, folder)\n",
    "IO.save_data_to_disk(FV_data, 'FV_data', file_header, folder)\n",
    "IO.save_data_to_disk(curated_cell_props, 'curated_cell_props', file_header, folder)\n",
    "IO.save_data_to_disk(sniff_data, 'sniff_table', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "176c5be1ba73ca5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Checkpoint 1"
   ],
   "id": "64e5643e669a0877"
  },
  {
   "cell_type": "code",
   "source": [
    "# Opens the saved pickle files.  If the files have already been saved, code can be re-run\n",
    "# starting from this point\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "curated_trace_data = IO.load_data_from_disk('curated_trace_data', file_header, folder)\n",
    "GPIO_data = IO.load_data_from_disk('GPIO_data', file_header, folder)\n",
    "FV_data = IO.load_data_from_disk('FV_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "\n",
    "cell_names = curated_cell_props['Name']  # List of cells, referenced periodically"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c706c8b64d42488",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### STEP 3: Isolate dF/F Data for Experiment"
   ],
   "id": "818076415b2bc312"
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 3A: Parses the final valve data to identify when the final valve is open vs when it is closed based on TTL pulse from Arduino.\n",
    "# In the EPM experiment, there is no final valve. However, we are using the same sync signal as used in the odor experiments to signal when the LED is triggered\n",
    "\n",
    "FV_values = FV_data['Value'].astype(float).values # Get FV Values\n",
    "num_values = len(FV_values)\n",
    "valve_status = 0\n",
    "FV_on_indexes = []\n",
    "FV_off_indexes = []\n",
    "for i in trange((num_values - 1), desc=\"Processing: \"):\n",
    "    valve_val_diff = FV_values[i + 1] - FV_values[i]\n",
    "\n",
    "    if valve_status == 0:    # Start with valve off\n",
    "        if valve_val_diff > 10000: # If the difference is a very large positive number, the valve opened\n",
    "            FV_on_indexes.append(i + 1)\n",
    "            valve_status = 1 # Set valve state to open\n",
    "    else:\n",
    "        if valve_val_diff < -10000: # If the difference is a very laarge negative number, the valve closed\n",
    "            FV_off_indexes.append(i)\n",
    "            valve_status = 0 # Set valve state to closed\n",
    "\n",
    "FV_indexes = pd.DataFrame(zip(FV_on_indexes, FV_off_indexes), columns=['On', 'Off'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5505d5ba98ede822",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 3B: Find trial start and end times with the pre/post trial offsets\n",
    "time_points = FV_data['Time(s)']\n",
    "\n",
    "FV_on_times = time_points.iloc[FV_indexes['On']]\n",
    "FV_off_times = time_points.iloc[FV_indexes['Off']]\n",
    "\n",
    "trial_times = pd.DataFrame(zip(FV_on_times, FV_off_times), columns=['Start', 'End'])"
   ],
   "id": "8a8d3e2a267dbce9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 3C: Trim dF/F data to the FV On and Off Times\n",
    "\n",
    "time_points = curated_trace_data.index.values\n",
    "\n",
    "cell_trace_start_indices = []\n",
    "cell_trace_stop_indices = []\n",
    "\n",
    "for name, (trial_start_time, trial_end_time) in trial_times.iterrows():\n",
    "    cell_trace_start_indices.append(np.where(time_points <= trial_start_time)[0][-1]) # Find first value less than/= the start time. We would always rather start 1 frame early than late\n",
    "    cell_trace_stop_indices.append(np.where(time_points >= trial_end_time)[0][0]) # Find the first value greater than/= the end time. We would always rather stop 1 frame late than early\n",
    "\n",
    "cell_trace_indices = pd.DataFrame(zip(cell_trace_start_indices, cell_trace_stop_indices), columns = ['Start', 'Stop'])"
   ],
   "id": "6fb92989d4d713ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 3D: Apply trial labels to all dataframes\n",
    "#num_trials = trial_times.shape[0]\n",
    "#trial_labels = HFvFM.get_trial_labels(num_trials, HF_first)\n",
    "\n",
    "if HF_first:\n",
    "    trial_labels = ['HF-1', 'FM-1', 'HF-2', 'FM-2']\n",
    "else:\n",
    "    trial_labels = ['FM-1', 'HF-1', 'FM-2', 'HF-2']\n",
    "\n",
    "FV_indexes.index = trial_labels\n",
    "trial_times.index = trial_labels\n",
    "cell_trace_indices.index = trial_labels"
   ],
   "id": "72ff6bb5e40f173c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### STEP 4: Combine All Data"
   ],
   "id": "4846aa3efa2bc76e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 4A: COMBINE ALL OF THE CELL TRACE DATA INTO A CELL X TRIAL X FRAMES ARRAY\n",
    "combined_data = []\n",
    "num_cells = len(cell_names)\n",
    "for cell in tqdm(cell_names, desc=\"Cell: \"): # Loop through each cell\n",
    "    cell_data = []\n",
    "\n",
    "    for indices in cell_trace_indices[['Start', 'Stop']].values: # Loop through trials\n",
    "        start_index, stop_index = indices\n",
    "        trial_data = curated_trace_data[cell].iloc[start_index:stop_index].reset_index(drop=True)\n",
    "        cell_data.append(trial_data)\n",
    "    cell_data = pd.DataFrame(cell_data, index=trial_labels).T  # Transpose dataframe so columns are trials and rows are frames\n",
    "    cell_data = cell_data.reset_index(drop=True)\n",
    "    combined_data.append(cell_data)\n",
    "\n",
    "# # STEP 4B: CROP THE ARRAY TO THE SHORTEST TRIAL TO GET RID OF TRAILING ZEROS\n",
    "combined_data = pd.concat(combined_data, axis=1, keys=cell_names, names=['Cells', 'Frames'])\n",
    "# # combined_data = combined_data.dropna(axis=0)\n",
    "\n",
    "# STEP 4C (Optional): BASELINE SHIFT THE DATA SO THERE ARE NO NEGATIVE NUMBERS\n",
    "min_value = abs(combined_data.min().min()) # Get minimum for each row, then the minimum of those values\n",
    "combined_data_shift = combined_data.add(min_value)"
   ],
   "id": "b1856e4cd9098df6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Step 5: Save Data"
   ],
   "id": "761558840c3623c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 5A: CREATE TABLE OF CONTENTS FOR CELL DESCRIPTORS\n",
    "column_names = ['Name', 'CentroidX', 'CentroidY', 'NumComponents', 'Size']\n",
    "toc = curated_cell_props[column_names]\n",
    "toc = toc.set_index('Name', drop=True)\n",
    "\n",
    "# STEP 5B: SET FILE PATH AND CREATE EXCEL-SHEET WRITER\n",
    "file_name = f'{file_header}CombinedData.xlsx'\n",
    "path = project_folder.analysis_dir.combined_dir.path.joinpath(file_name)\n",
    "writer = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "\n",
    "# STEP 5C: WRITE TABLE OF CONTENTS\n",
    "toc.to_excel(writer, sheet_name='TOC')\n",
    "\n",
    "# STEP 5E: WRITE ALL CELL TRACE DATA\n",
    "for cell in tqdm(cell_names, desc=\"Writing Cell: \"):\n",
    "    _data = combined_data_shift[cell]\n",
    "    _data.to_excel(writer, sheet_name=f'Cell {cell}')\n",
    "\n",
    "writer.close()"
   ],
   "id": "56166d708d23a490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "collapsed": false
   },
   "cell_type": "code",
   "source": [
    "# STEP 5F: Save Combined Data and Indices/Times\n",
    "\n",
    "folder = project_folder.analysis_dir.combined_dir.path\n",
    "IO.save_data_to_disk(combined_data, 'combined_data', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "IO.save_data_to_disk(FV_indexes, 'FV_indexes', file_header, folder)\n",
    "IO.save_data_to_disk(trial_times, 'trial_times', file_header, folder)\n",
    "IO.save_data_to_disk(cell_trace_indices, 'cell_trace_indices', file_header, folder)\n",
    "IO.save_data_to_disk(trial_labels, 'trial_labels', file_header, folder)\n"
   ],
   "id": "a2c8dc5974fbab93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ========== STOP HERE ==========",
   "id": "4d4c2c3ef04debd5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CHECKPOINT 2",
   "id": "af0575ecbec706d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.combined_dir.path\n",
    "\n",
    "combined_data = IO.load_data_from_disk('combined_data', file_header, folder)\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "trial_labels = IO.load_data_from_disk('trial_labels', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "id": "dc876c81d6ffe3a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## STEP 6: Deconvolve Traces and Identify Transients",
   "id": "2c4a8e4824cf9546"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6A: Smooth raw df/F values with OASIS\n",
    "smoothing_kernel = deconv.calc_smoothing_params(ENDOSCOPE_FRAMERATE, DECAY_TIME_S, RISE_TIME_S)\n",
    "smoothed_trace_data = deconv.pooled_deconvolution(combined_data, smoothing_kernel)"
   ],
   "id": "b4f10fec385974cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6B: Identify transients\n",
    "z_scored_data = deconv.z_score_data(smoothed_trace_data, cell_names)\n",
    "transient_indexes = deconv.find_peaks(z_scored_data, cell_names, ENDOSCOPE_FRAMERATE, INTER_SPIKE_INTERVAL_S, PEAK_MIN_DUR_S, )"
   ],
   "id": "a51a7eabb2b82a12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6C: Get Stats for Each Cell\n",
    "for cell in cell_names:\n",
    "    cell_data = transient_indexes[cell]\n",
    "\n",
    "    stats = HFvFM.calc_transient_stats(cell_data, trial_labels)\n",
    "\n",
    "    cell_data['stats'] = stats\n",
    "    transient_indexes[cell] = cell_data"
   ],
   "id": "cd6e2ca82694f11e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEPS 6D: Stack Trials from each Cell\n",
    "stacked_indices = HFvFM.stack_trial_indices(trial_labels, cell_names, transient_indexes)"
   ],
   "id": "cf12a83b24f7231f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6E: Offset each trial to match its trial\n",
    "from functools import partial\n",
    "\n",
    "trial_length_frames = ENDOSCOPE_FRAMERATE * TRIAL_DURATION_S\n",
    "\n",
    "for i, trial in enumerate(trial_labels):\n",
    "    if i > 0:\n",
    "        offset_value = i * trial_length_frames  # Max trial length\n",
    "        print(f'{trial}: {offset_value}')\n",
    "\n",
    "        temp_func = partial(HFvFM.add_if_num, i*offset_value)\n",
    "        trial_dataframe = stacked_indices[trial]\n",
    "        stacked_indices[trial] = trial_dataframe.map(temp_func)\n",
    "\n",
    "    stacked_indices[trial] = stacked_indices[trial].T\n",
    "    stacked_indices[trial].index=cell_names"
   ],
   "id": "4ecc9683239fb25a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6F: Combine Stats into a DataFrame\n",
    "cell_stats = {}\n",
    "for cell in cell_names:\n",
    "    cell_stats[cell] = transient_indexes[cell]['stats']\n",
    "cell_stats = pd.DataFrame(cell_stats).T"
   ],
   "id": "7bdc1b250d053642",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6G: Combine Stats, Transients, and Remove Spaces\n",
    "\n",
    "super_mega_ultra_df = pd.DataFrame()\n",
    "for trial in trial_labels:\n",
    "    trial_df = stacked_indices[trial]\n",
    "    num_columns = len(trial_df.columns)\n",
    "    new_columns = [trial for _ in range(num_columns)]\n",
    "    trial_df.columns = new_columns\n",
    "    super_mega_ultra_df = pd.concat([super_mega_ultra_df, trial_df], axis=1)\n",
    "\n",
    "super_mega_ultra_df = super_mega_ultra_df.apply(lambda row: pd.Series(row.dropna().values), axis=1)  # Voodoo to remove NaN values\n",
    "super_mega_ultra_df = pd.concat((cell_stats, super_mega_ultra_df), axis=1)\n",
    "\n",
    "file_name = f'{file_header}TransientLocations.xlsx'\n",
    "path = project_folder.analysis_dir.output_dir.path.joinpath(file_name)\n",
    "\n",
    "super_mega_ultra_df.to_excel(path)"
   ],
   "id": "e34715639f700d00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 6H: Save deconv data\n",
    "folder = project_folder.analysis_dir.output_dir.subdir('deconv')\n",
    "\n",
    "IO.save_data_to_disk(smoothed_trace_data, 'smoothed_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(z_scored_data, 'z_scored_data', file_header, folder)\n",
    "IO.save_data_to_disk(transient_indexes, 'transient_indexes', file_header, folder)"
   ],
   "id": "11e121f724e3418",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Checkpoint 3",
   "id": "12ee5b1d2df6700c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "trial_labels = IO.load_data_from_disk('trial_labels', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']\n",
    "\n",
    "folder = project_folder.analysis_dir.combined_dir.path\n",
    "combined_data = IO.load_data_from_disk('combined_data', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.output_dir.subdir('deconv')\n",
    "smoothed_trace_data = IO.load_data_from_disk('smoothed_trace_data', file_header, folder)\n",
    "z_scored_data = IO.load_data_from_disk('z_scored_data', file_header, folder)\n",
    "transient_indexes = IO.load_data_from_disk('transient_indexes', file_header, folder)"
   ],
   "id": "501038e47fa09952",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7: Pseudotrial creation and auROC Analysis",
   "id": "995c8550f343c6bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 7A: BASELINE SHIFT THE DATA SO THERE ARE NO NEGATIVE NUMBERS\n",
    "min_value = abs(combined_data.min().min()) # Get minimum for each row, then the minimum of those values\n",
    "combined_data_shift = combined_data.add(min_value)"
   ],
   "id": "6c0ff04157cf10ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 7B: Get Pseudotrials and stack the data\n",
    "pseudotrial_dff_per_cell = HFvFM.get_dff_for_pseudotrials(combined_data_shift, cell_names, trial_labels, PSEUDOTRIAL_LEN_S, ENDOSCOPE_FRAMERATE)\n",
    "stacked_pseudotrials = HFvFM.stack_trial_indices(trial_labels, cell_names, pseudotrial_dff_per_cell)"
   ],
   "id": "1541fe7b555cfc7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 7C: Get mean dF/F value for each trial\n",
    "pseudotrial_means = {}\n",
    "\n",
    "for trial in trial_labels:\n",
    "    trial_data = stacked_pseudotrials[trial].T\n",
    "    trial_means = trial_data.map(np.mean)\n",
    "    trial_means.index = cell_names\n",
    "    pseudotrial_means[trial] = trial_means"
   ],
   "id": "57ee6d0338be0da3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 7D: Run auROC on below groups and save data\n",
    "groups = [['HF-1', 'HF-2'], ['FM-1', 'FM-2']]\n",
    "auroc_returns = AUROC.pooled_HFFM_auroc(pseudotrial_means, groups, num_workers=20)\n",
    "\n",
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "IO.save_data_to_disk(auroc_returns, 'auroc_returns', file_header, folder)"
   ],
   "id": "b476de461314da78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CHECKPOINT 4",
   "id": "f905ce5c0f15644d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "auroc_returns = IO.load_data_from_disk('auroc_returns', file_header, folder)"
   ],
   "id": "d419233581d9c635",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 8: Create figures and save data",
   "id": "83f2e8edeec75c54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 8A: Plot auROC Figures\n",
    "plotting.plot_auroc_distribution(auroc_returns, project_folder)\n",
    "plotting.plot_auroc_shuffles(auroc_returns, project_folder)"
   ],
   "id": "dc52eefb336b94cf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## STEP 8B: Restructure returned items into a dataframe and save\n",
    "auroc_return_dict = {}\n",
    "\n",
    "for cell_data in auroc_returns:\n",
    "    cell_name = cell_data['name']\n",
    "    cell_data.pop('name', None)\n",
    "    \n",
    "    auroc_val = round(cell_data['auroc'], 3)\n",
    "    direction_index = round(2 * (auroc_val - 0.5), 2)\n",
    "    \n",
    "    cell_data['auroc'] = auroc_val\n",
    "    cell_data['direction_index'] = direction_index\n",
    "    \n",
    "    auroc_return_dict[cell_name] = cell_data\n",
    "    \n",
    "HFvFM_df = pd.DataFrame(auroc_return_dict).T\n",
    "folder = project_folder.analysis_dir.output_dir.path\n",
    "file_name = f'{file_header}HFvFM_data_output.xlsx'\n",
    "file_path = folder.joinpath(file_name)\n",
    "HFvFM_df.to_excel(file_path)"
   ],
   "id": "b89a2455fd6158da",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
