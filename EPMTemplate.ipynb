{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1471a0c2b0c3e8ed",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Dewan Lab EPM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5d20e6bdd90448",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import os\n",
    "os.environ['ISX'] = '0'  # Set to zero so we don't try to load the isx module\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from dewan_calcium import plotting\n",
    "from dewan_calcium.helpers import IO, parse_json, EPM\n",
    "from dewan_calcium.helpers.project_folder import ProjectFolder\n",
    "\n",
    "print(\"Importing required packages complete!\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2cbadb82b6bdf09c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### STEP 1B: User Configurables"
   ]
  },
  {
   "cell_type": "code",
   "id": "d17c61cc38601c39",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "manual_start_frame = []  \n",
    "# If DLC does a poor job tracking the LED, estimate the start frame by multiplying the time stamp by 60(FPS) to get an estimated start frame\n",
    "\n",
    "EXPERIMENT_TIME = 10 # minutes\n",
    "LED_CUTOFF = 0.95 # p-value cut off\n",
    "NUM_PSEUDOTRIALS = 12  # Number of pseudotrials to subsample from each cell\n",
    "TRIM_END_S = 0  # Number of seconds to remove from the end of the data; equivalent to data = data[:-(TRIM_END_S * FPS)]\n",
    "\n",
    "EXCLUDE_PSEUDOTRIAL_SHORT_CELLS = False  # Set to true to exclude cells that do not satisfy number_of_cell_pseudotrials >= NUM_PSEUDOTRIALS \n",
    "SAVE_LOAD_RNG_ENTROPY = False # If we want the \"randomly sampled\" pseudotrials to be the same every time the notebook is run, the seed for the random number generator needs to be saved\n",
    "\n",
    "# === CONSTANTS === #\n",
    "PSEUDOTRIAL_LEN_S = 2 # duration of pseudotrial in seconds\n",
    "OPEN_ARM_LENGTH_CM = 79  # Measured\n",
    "MAX_MOUSE_SPEED = 1  # m/s"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "743384ae8afd7f4a",
   "metadata": {},
   "source": [
    "### STEP 1C: Load Project Folder"
   ]
  },
  {
   "cell_type": "code",
   "id": "b153d57361969394",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Create Project Folder to Gather and Hold all the File Paths\n",
    "\n",
    "project_folder = ProjectFolder('EPM')\n",
    "file_header = animal + '-' + date + '-'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8335d89603fe71ef",
   "metadata": {},
   "source": [
    "# If this is the first time the project folder has been created,\n",
    "# move the files to the appropriate directories and then run this cell, otherwise skip this cel\n",
    "project_folder.get_data()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4181d09c235c41ad",
   "metadata": {},
   "source": [
    "# Get settings from imaging session and display them for the user\n",
    "\n",
    "gain, LED_power, ENDOSCOPE_FRAMERATE, focal_planes = parse_json.get_session_settings(project_folder.raw_data_dir.session_json_path)\n",
    "\n",
    "print(f'Recording Gain: {gain}')\n",
    "print(f'Endoscope Framerate: {ENDOSCOPE_FRAMERATE}')\n",
    "print(f'LED Power: {LED_power}')\n",
    "print(f'Focal Plane(s): {focal_planes}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8e0375d9126c67a",
   "metadata": {},
   "source": [
    "## 2A: Import and pre-process the raw data"
   ]
  },
  {
   "cell_type": "code",
   "id": "a9b3d146c77c791e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#STEP 2A.1: LOAD DLC DATA\n",
    "\n",
    "tracked_points = pd.read_hdf(project_folder.raw_data_dir.points_h5_path)  # Load tracked points\n",
    "labeled_video = cv2.VideoCapture(str(project_folder.raw_data_dir.labeled_video_path))  # Load Video\n",
    "VIDEO_FPS = labeled_video.get(cv2.CAP_PROP_FPS)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "abd14e642db457ce",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#STEP 2A.2: LOAD INSCOPIX DATA\n",
    "\n",
    "cell_trace_data = pd.read_csv(project_folder.inscopix_dir.cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(project_folder.inscopix_dir.GPIO_path, header=0, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(project_folder.inscopix_dir.props_path, header=0, engine='pyarrow')\n",
    "cell_outlines = parse_json.get_outline_coordinates(project_folder.inscopix_dir.contours_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1c367711c48588a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# STEP 2A.3: PREPROCESSING\n",
    "\n",
    "# STEP 2A.3.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data = cell_trace_data.drop([0])\n",
    "\n",
    "# STEP 2A.3.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data = cell_trace_data.set_index(cell_trace_data.columns[0]) \n",
    "\n",
    "# STEP 2A.3.3: Remove spaces from column names and contents\n",
    "cell_trace_data.columns = cell_trace_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data.columns = GPIO_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data['ChannelName'] = GPIO_data['ChannelName'].str.replace(\" \", \"\")\n",
    "\n",
    "# STEP 2A.3.4: Reduce properties to only include the cells with only one component\n",
    "all_cell_props = all_cell_props[all_cell_props['NumComponents']==1]  # We only want cells that have one component\n",
    "all_cell_props = all_cell_props.drop(columns='Status').reset_index(drop=True)\n",
    "cell_names = all_cell_props['Name'].values\n",
    "\n",
    "# STEP 2A.3.5: PARSE GPIO DATA\n",
    "sniff_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-1\"].reset_index(drop=True)\n",
    "FV_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-2\"].reset_index(drop=True)\n",
    "\n",
    "# OPTIONAL UNUSED DATA\n",
    "# running_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-3\"]  # Running Wheel Data\n",
    "# lick_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-4\"]  # Lick Data"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f314d311576ad6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# STEP 2A.4: PREPROCESS DLC Data\n",
    "\n",
    "num_cols = len(tracked_points.columns)\n",
    "\n",
    "if num_cols == 6:\n",
    "    cols = ['mouse_x', 'mouse_y', 'mouse_p', 'led_x', 'led_y', 'led_p'] \n",
    "elif num_cols == 9:\n",
    "    cols = ['mouse_x', 'mouse_y', 'mouse_p', 'body_x', 'body_y', 'body_p', 'led_x', 'led_y', 'led_p'] \n",
    "\n",
    "# Reset the column names to something sensible\n",
    "tracked_points.columns = cols "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e21d1f96278b274b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## STEP 2B: Manual Curation"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6d6c2c8fc4f07b6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from dewan_manual_curation import dewan_manual_curation\n",
    "\n",
    "curated_cells = dewan_manual_curation.launch_gui(project_folder_override=project_folder, cell_trace_data_override=cell_trace_data, cell_props_override=all_cell_props, cell_contours_override=cell_outlines)\n",
    "if not curated_cells:\n",
    "    print('Error, no good cells selected!')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aba514ce06958860",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### STEP 2C: Apply Manual Curation Results and Additional Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "id": "6d4ee4dc735b1d81",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# STEP 2C.1: Filter all data by the GoodCells identified in ManualCuration\n",
    "\n",
    "curated_cell_props = all_cell_props[all_cell_props['Name'].isin(curated_cells)].reset_index(drop=True)\n",
    "curated_trace_data = cell_trace_data[curated_cells]\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# STEP 2C.2 (Optional): Trim time from end of data if TRIM_END_S is set\n",
    "if TRIM_END_S > 0:\n",
    "    num_frames = curated_trace_data.shape[0]\n",
    "    exp_length_frames = EXPERIMENT_TIME * 60 * ENDOSCOPE_FRAMERATE  # Time in minutes * 60 s/min * frames/s\n",
    "    frames_to_trim = ENDOSCOPE_FRAMERATE * TRIM_END_S\n",
    "    new_total_frames = num_frames - frames_to_trim\n",
    "    print(f'Total Fluorescence Frames: {num_frames}; Experiment Length Frames: {exp_length_frames}; Frames to Trim: {frames_to_trim}\\n'\n",
    "          f'New Total Fluorescence Frames: {new_total_frames}')\n",
    "    if new_total_frames < exp_length_frames:\n",
    "        raise ValueError('You cannot trim the fluorescence data to be shorter than the experiment length. \\n'\n",
    "                         'Reduce EXPERIMENT_TIME to make the total experiment shorter, or reduce TRIM_END_S so less data is trimmed!')\n",
    "    \n",
    "    curated_trace_data = curated_trace_data.iloc[:frames_to_trim, :]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2192c90b73d8c0d1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bec801c85b27c1bb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### STEP 2D: Pickle and Save all preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "id": "176c5be1ba73ca5e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pickle the reorganized CellTraceData incase its needed later\n",
    "# Saves Cell Traces, GPIO, Odor List, Sniff, FV data, Good Cell Properties, Good Cells, and the labeled max projection\n",
    "# Once these have been saved, they don't need to be re-run on the same data again unless the data itself is changed\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(curated_trace_data, 'curated_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(GPIO_data, 'GPIO_data', file_header, folder)\n",
    "IO.save_data_to_disk(FV_data, 'FV_data', file_header, folder)\n",
    "IO.save_data_to_disk(curated_cell_props, 'curated_cell_props', file_header, folder)\n",
    "IO.save_data_to_disk(sniff_data, 'sniff_table', file_header, folder)\n",
    "\n",
    "IO.save_data_to_disk(tracked_points, 'tracked_points', file_header, folder)\n",
    "IO.save_data_to_disk(VIDEO_FPS, 'VIDEO_FPS', file_header, folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "64e5643e669a0877",
   "metadata": {},
   "source": [
    "### Checkpoint 1"
   ]
  },
  {
   "cell_type": "code",
   "id": "6c706c8b64d42488",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Opens the saved pickle files.  If the files have already been saved, code can be re-run\n",
    "# starting from this point\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "curated_trace_data = IO.load_data_from_disk('curated_trace_data', file_header, folder)\n",
    "GPIO_data = IO.load_data_from_disk('GPIO_data', file_header, folder)\n",
    "FV_data = IO.load_data_from_disk('FV_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "sniff_data = IO.load_data_from_disk('sniff_table', file_header, folder)\n",
    "\n",
    "cell_names = curated_cell_props['Name']  # List of cells, referenced periodically\n",
    "\n",
    "tracked_points = IO.load_data_from_disk('tracked_points', file_header, folder)\n",
    "VIDEO_FPS = IO.load_data_from_disk('VIDEO_FPS', file_header, folder)\n",
    "\n",
    "folder = project_folder.raw_data_dir.path\n",
    "labeled_video = cv2.VideoCapture(str(project_folder.raw_data_dir.labeled_video_path))  # Load Video"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a569d95d9d8f702a",
   "metadata": {},
   "source": [
    "### STEP 3: Process DLC Output and Get EPM Bounds"
   ]
  },
  {
   "cell_type": "code",
   "id": "e1e30f041e79b4f3",
   "metadata": {},
   "source": [
    "# STEP 3A: Get True Start/End Time of Experiment\n",
    "# There may be an instance where the model erroneously identified the LED for very short time periods\n",
    "# find_index_bins returns the LED on and off bins (anywhere led_p > 0.98)\n",
    "# true_led_bin ensures that the \"true\" start bin is selected and the \"end\" bin is not erroneously selected\n",
    "\n",
    "if not manual_start_frame:\n",
    "    LED_indexes = tracked_points.index[tracked_points['led_p'] > LED_CUTOFF].values\n",
    "    led_bins = EPM.find_index_bins(LED_indexes)\n",
    "    true_led_bin = EPM.get_true_bin_index(led_bins, len(tracked_points))\n",
    "    led_on = true_led_bin[0] # The first instance where the LED is 'on'\n",
    "else:\n",
    "    led_on = manual_start_frame\n",
    "    \n",
    "experiment_frames = int(VIDEO_FPS * 60 * EXPERIMENT_TIME)  # FPS * 60 s/min * experiment length in minutes --> number of frames\n",
    "end_frame = led_on + experiment_frames\n",
    "good_points = tracked_points.iloc[led_on:end_frame] # Subset the frames from LED_ON -> EXPERIMENT_TIME minutes later\n",
    "good_points = good_points.reset_index(drop=True) # Reset the index\n",
    "\n",
    "# Get X, Y coordinates, cast to int, and combine them into tuples\n",
    "head_x = good_points['mouse_x'].astype(int)\n",
    "head_y = good_points['mouse_y'].astype(int)\n",
    "coordinates = [list(item) for item in zip(head_x, head_y)]\n",
    "coordinates = np.array(coordinates)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5df7278d66c3a44c",
   "metadata": {},
   "source": [
    "## STEP 3B: Display ROI Instructions\n",
    "\n",
    "EPM.display_roi_instructions()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96cf97e3f4cf7f50",
   "metadata": {},
   "source": [
    "## STEP 3C.1: Get user to label open and closed arms\n",
    "\n",
    "%matplotlib qt  \n",
    "# Opens the matplotlib window using the QT backend\n",
    "\n",
    "labeled_video.set(cv2.CAP_PROP_POS_FRAMES, led_on - 1) # Pull the frame that is our actual start\n",
    "_, background_image = labeled_video.read()\n",
    "\n",
    "arm_coordinates = EPM.get_arm_rois(background_image)\n",
    "\n",
    "# Switch back to using inline displays\n",
    "%matplotlib inline\n",
    "\n",
    "## STEP 3C.2: Split two arms into the five regions\n",
    "individual_regions, original_regions = EPM.get_region_polygons(arm_coordinates)  \n",
    "# ([open_arm_1, open_arm_2, closed_arm_1, closed_arm_2, center_polygon], [open_arm, closed_arm, center])\n",
    "\n",
    "## STEP 3C.3: Display image of EPM\n",
    "fig, ax = plotting.plot_epm_roi(original_regions, background_image)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "56fc67dacadc4b19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aba50cd36f4a6917",
   "metadata": {},
   "source": [
    "### STEP 3D (Optional): Interpolate jumps in animal's position"
   ]
  },
  {
   "cell_type": "code",
   "id": "3936e033ac8d7e48",
   "metadata": {},
   "source": [
    "## Step 3D.1: Calculate Maximum Speed of Mouse in (pixels / frame)\n",
    "\n",
    "open_arm_length_px = original_regions.loc['open_arm'].Length\n",
    "mouse_max_movement_threshold = round(MAX_MOUSE_SPEED * 100 / OPEN_ARM_LENGTH_CM * open_arm_length_px / VIDEO_FPS, 3)  \n",
    "# Max Mouse Speed (m/s) * 100 (cm/m) / 79 (cm/open arm) * Length of Open Arm (pixels) / video FPS (FPS) \n",
    "\n",
    "# STEP 3D.2: Interpolate jumps in animal's position \n",
    "# Run this cell to interpolate large distance jumps in the DLC tracking data\n",
    "thresh, num_jumps, coordinates = EPM.interpolate_DLC_coordinates(coordinates, threshold=mouse_max_movement_threshold) \n",
    "print(f\"There were {num_jumps} jumps that required interpolation.\")\n",
    "print(f\"The interpolation threshold used was {thresh}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "d5bade0a5da9b5cf",
   "metadata": {},
   "source": [
    "### STEP 3E: Save EPM Regions "
   ]
  },
  {
   "cell_type": "code",
   "id": "550c560da3ad0cfc",
   "metadata": {},
   "source": [
    "## Save the ROIs and image\n",
    "\n",
    "folder = project_folder.analysis_dir.figures_dir.subdir('EPM_ROI')\n",
    "\n",
    "image_path = folder.joinpath('EPM_ROI.pdf')\n",
    "fig.savefig(str(image_path), dpi=600)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.subdir('EPM_ROI')\n",
    "IO.save_data_to_disk(arm_coordinates, 'arm_coordinates', file_header, folder)\n",
    "IO.save_data_to_disk(individual_regions, 'individual_regions', file_header, folder)\n",
    "IO.save_data_to_disk(original_regions, 'original_regions', file_header, folder)\n",
    "IO.save_data_to_disk(background_image, 'background_image', file_header, folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "818076415b2bc312",
   "metadata": {},
   "source": [
    "### STEP 4: Isolate dF/F Data for Experiment"
   ]
  },
  {
   "cell_type": "code",
   "id": "5505d5ba98ede822",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# STEP 4A: Parses the final valve data to identify when the final valve is open vs when it is closed based on TTL pulse from Arduino.\n",
    "# In the EPM experiment, there is no final valve. However, we are using the same sync signal as used in the odor experiments to signal when the LED is triggered\n",
    "\n",
    "FV_values = FV_data['Value'].astype(float).values # Get FV Values\n",
    "num_values = len(FV_values)\n",
    "valve_status = 0\n",
    "FV_on_indexes = []\n",
    "FV_off_indexes = []\n",
    "for i in trange((num_values - 1), desc=\"Processing: \"):\n",
    "    valve_val_diff = FV_values[i + 1] - FV_values[i]\n",
    "\n",
    "    if valve_status == 0:    # Start with valve off\n",
    "        if valve_val_diff > 10000: # If the difference is a very large positive number, the valve opened\n",
    "            FV_on_indexes.append(i + 1)\n",
    "            valve_status = 1 # Set valve state to open\n",
    "    else:\n",
    "        if valve_val_diff < -10000: # If the difference is a very laarge negative number, the valve closed\n",
    "            FV_off_indexes.append(i)\n",
    "            valve_status = 0 # Set valve state to closed\n",
    "\n",
    "FV_indexes = pd.DataFrame(zip(FV_on_indexes, FV_off_indexes), columns=['On', 'Off'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "60552b9f3540b418",
   "metadata": {},
   "source": [
    "# STEP 4B: Trim dF/F data to the FV On and Off Times\n",
    "\n",
    "experiment_start_index = FV_indexes['On'][0]\n",
    "FV_timestamps = FV_data['Time(s)']\n",
    "trial_start_time = FV_timestamps[experiment_start_index]  # Trial start time in unix time (s)\n",
    "trial_end_time = trial_start_time + (EXPERIMENT_TIME * 60)  # End time is whatever the duration of the experiment was in minutes\n",
    "\n",
    "cell_trace_times = curated_trace_data.index.values\n",
    "\n",
    "cell_trace_on_index = np.where(cell_trace_times <= trial_start_time)[0][-1]\n",
    "cell_trace_off_index = np.where(cell_trace_times <= trial_end_time)[0][-1]  # We can't overshoot otherwise the coordinate will not match, so we may drop a single frame\n",
    "\n",
    "trimmed_trace_data = curated_trace_data.iloc[cell_trace_on_index:cell_trace_off_index, :]\n",
    "\n",
    "trimmed_cell_trace_times = trimmed_trace_data.index.values\n",
    "shifted_cell_trace_times = np.subtract(trimmed_cell_trace_times, trimmed_cell_trace_times[0])\n",
    "rounded_cell_trace_times = np.round(shifted_cell_trace_times, 2)\n",
    "\n",
    "trimmed_trace_data.index = rounded_cell_trace_times\n",
    "\n",
    "good_points_index = good_points.index.values\n",
    "good_points_time = np.divide(good_points_index, VIDEO_FPS)\n",
    "good_points_time = np.round(good_points_time, 2)\n",
    "good_points.index = good_points_time"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc586f8e96da691c",
   "metadata": {},
   "source": [
    "## Step 4C: Align Cell Traces with the DLC Data\n",
    "## Since the DLC data is typically recorded at 6X the rate as the neural data, there is typically multiple data points we can choose for the coordinate of a trace\n",
    "## For simplicity, we will pick the coordinate that exactly matches the time point of the trace\n",
    "## In the future we can do some averaging or picking the median, etc. \n",
    "\n",
    "trace_coordinate_indexes = []\n",
    "good_points_index = good_points.index.values\n",
    "\n",
    "for time in tqdm(trimmed_trace_data.index):  # Check each \n",
    "    coordinate_index = np.where(good_points.index <= time)[0][-1]\n",
    "    trace_coordinate_indexes.append(coordinate_index)\n",
    "\n",
    "trace_coordinates = coordinates[trace_coordinate_indexes]\n",
    "trace_coordinates = trace_coordinates.tolist()\n",
    "trimmed_trace_data.insert(0, 'Coordinate_Index', trace_coordinate_indexes)\n",
    "trimmed_trace_data.insert(0, 'Coordinates', trace_coordinates)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "761558840c3623c8",
   "metadata": {},
   "source": [
    "## Step 4D: Save trace data"
   ]
  },
  {
   "cell_type": "code",
   "id": "a2c8dc5974fbab93",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Save the paired coordinates - trace data\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(trimmed_trace_data, 'trimmed_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(true_led_bin, 'true_led_bin', file_header, folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "af0575ecbec706d7",
   "metadata": {},
   "source": [
    "## CHECKPOINT 2"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc876c81d6ffe3a3",
   "metadata": {},
   "source": [
    "## Load the ROIs and image\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.subdir('EPM_ROI')\n",
    "arm_coordinates = IO.load_data_from_disk('arm_coordinates', file_header, folder)\n",
    "individual_regions = IO.load_data_from_disk('individual_regions', file_header, folder)\n",
    "original_regions = IO.load_data_from_disk('original_regions', file_header, folder)\n",
    "background_image = IO.load_data_from_disk('background_image', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "trimmed_trace_data = IO.load_data_from_disk('trimmed_trace_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa2a483aef115aac",
   "metadata": {},
   "source": [
    "## STEP 5: Associate coordinates with arms"
   ]
  },
  {
   "cell_type": "code",
   "id": "969025068905880",
   "metadata": {},
   "source": [
    "## STEP 5A: Find the arm each coordinate is located in\n",
    "# Get region for each time point and distance from occupied region\n",
    "\n",
    "animal_coordinates = trimmed_trace_data['Coordinates']\n",
    "coordinate_locations, region_indexes = EPM.get_regions(animal_coordinates, individual_regions) # What region each (x, y) is in"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9879ea179baa99d1",
   "metadata": {},
   "source": [
    "## STEP 5B (Optional): Interpolate the locations classified at \"The_Void\"\n",
    "# Run this cell if you would like to interpolate any position that fell outside the 5 regions\n",
    "\n",
    "void_indexes = np.where(coordinate_locations == \"The_Void\")[0]  # \"The_Void\" is the location assigned to points that fall outside of the five regions (open1, open2, closed1, closed2, center). This can occur if the animal looks over the side of the open arms\n",
    "void_index_bins = EPM.find_index_bins(void_indexes)\n",
    "coordinate_locations, region_indexes = EPM.replace_the_void(coordinate_locations, region_indexes, void_index_bins)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "2fa976779064c28d",
   "metadata": {},
   "source": [
    "## STEP 5C (Optional): Get distance into each arm\n",
    "# Optional: Run this cell if you would like to calculate the \"distance\" into the arm the animal has traveled\n",
    "\n",
    "coordinate_pairs = list(zip(animal_coordinates, region_indexes))\n",
    "distances = EPM.get_distances(individual_regions, coordinate_pairs)  # Return distance from animal -> occupied region\n",
    "# distances = EPM.normalize_distance(individual_regions, coordinate_locations, distances)\n",
    "# If desired, the distances can be normalized to the length of the arms. All positions become 'percentages' of the length along the arm\n",
    "trimmed_trace_data.insert(0, 'Distance', distances)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6f0fca04d71fcbfa",
   "metadata": {},
   "source": [
    "## STEP 5D: Add animal Location to the main list of trace data\n",
    "\n",
    "trimmed_trace_data.insert(0, 'Location', coordinate_locations)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2c4a8e4824cf9546",
   "metadata": {},
   "source": [
    "## STEP 6: Create 'PSEUDOTRIALS'"
   ]
  },
  {
   "cell_type": "code",
   "id": "609992a8e527d75f",
   "metadata": {},
   "source": [
    "## STEP 6A: Find transitions from region -> region\n",
    "# Gather all visits per each region\n",
    "# Calculate some statistics about our 'pseudotrials'\n",
    "\n",
    "animal_locations = trimmed_trace_data['Location']\n",
    "transitions, arm_indexes = EPM.find_region_transitions(animal_locations)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rng_seed = None\n",
    "\n",
    "if SAVE_LOAD_RNG_ENTROPY:  # If we are saving/loading\n",
    "    folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "    try:\n",
    "        entropy_value = IO.load_data_from_disk('entropy_value', file_header, folder)  # If we have a saved value, load it; otherwise, returns None\n",
    "        print('Found entropy file, reloading old seed!')\n",
    "        rng_seed = np.random.SeedSequence(entropy=entropy_value)\n",
    "    except FileNotFoundError as fnfe:\n",
    "        print('Entropy file not found. Creating new seed!')\n",
    "        # If no entropy value, create a new sequence and save the value\n",
    "        rng_seed = np.random.SeedSequence()\n",
    "        entropy_value = rng_seed.entropy\n",
    "        IO.save_data_to_disk(entropy_value, 'entropy_value', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d965814d635b59c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa56fc7f4c1d09",
   "metadata": {},
   "source": [
    "## STEP 6B.1: Segment transitions into trials that meet the PSEUDOTRIAL_LEN_S length criteria\n",
    "\n",
    "pseudotrials, trial_stats = EPM.get_pseudotrials(arm_indexes, transitions, PSEUDOTRIAL_LEN_S, ENDOSCOPE_FRAMERATE)\n",
    "\n",
    "pseudotrials = EPM.subsample_pseudotrials(pseudotrials, NUM_PSEUDOTRIALS, rng_seed)\n",
    "## STEP 6B.2: Print PSEUDOTRIAL Stats\n",
    "pseudotrial_stats = EPM.calc_pseudotrial_stats(pseudotrials, trial_stats)\n",
    "\n",
    "EPM.print_pseudotrial_stats(pseudotrial_stats)\n",
    "EPM.save_pseudotrial_stats(pseudotrial_stats, project_folder)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "49f63580fa9f64bc",
   "metadata": {},
   "source": [
    "## STEP 6C: Gather the dF/F values for each pseudotrial\n",
    "\n",
    "pseudotrial_traces = {\n",
    "    'open1': [],\n",
    "    'open2': [],\n",
    "    'closed1': [],\n",
    "    'closed2': []\n",
    "}\n",
    "\n",
    "frames_per_pseudotrial = int(np.floor(PSEUDOTRIAL_LEN_S * ENDOSCOPE_FRAMERATE)) \n",
    "\n",
    "for arm in pseudotrials:\n",
    "    arm_visits = pseudotrials[arm]\n",
    "    \n",
    "    for visit in arm_visits:\n",
    "        start_index = visit['start']\n",
    "        end_index = start_index + frames_per_pseudotrial\n",
    "        traces = trimmed_trace_data[cell_names].iloc[start_index:end_index]\n",
    "        # We first grab the columns for the cells and then grab the rows for our trial\n",
    "        pseudotrial_traces[arm].append(traces)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6fe4ab81d041f50b",
   "metadata": {},
   "source": [
    "## STEP 6D: Get mean dF/F values for each trial\n",
    "\n",
    "pseudotrial_means = {\n",
    "    'open1': pd.DataFrame(),\n",
    "    'open2': pd.DataFrame(),\n",
    "    'closed1': pd.DataFrame(),\n",
    "    'closed2': pd.DataFrame(),\n",
    "}\n",
    "\n",
    "for arm in pseudotrial_means:\n",
    "    for trial in pseudotrial_traces[arm]:\n",
    "        pseudotrial_means[arm] = pd.concat((pseudotrial_means[arm], trial.mean(axis=0)), axis=1)\n",
    "    \n",
    "    pseudotrial_means[arm] = pseudotrial_means[arm].T\n",
    "    pseudotrial_means[arm] = pseudotrial_means[arm].reset_index(drop=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fa22524eb56db3bd",
   "metadata": {},
   "source": [
    "## Step 6E: Save PSUEDOTRIALS"
   ]
  },
  {
   "cell_type": "code",
   "id": "3153e57c56bd5167",
   "metadata": {},
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('pseudotrials')\n",
    "\n",
    "IO.save_data_to_disk(pseudotrials, 'pseudotrials', file_header, folder)\n",
    "IO.save_data_to_disk(trial_stats, 'trial_stats', file_header, folder)\n",
    "IO.save_data_to_disk(transitions, 'transitions', file_header, folder)\n",
    "IO.save_data_to_disk(arm_indexes, 'arm_indexes', file_header, folder)\n",
    "IO.save_data_to_disk(pseudotrial_traces, 'pseudotrial_traces', file_header, folder)\n",
    "IO.save_data_to_disk(pseudotrial_means, 'pseudotrial_means', file_header, folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "5b9b43be0de9c854",
   "metadata": {},
   "source": [
    "### Checkpoint 3"
   ]
  },
  {
   "cell_type": "code",
   "id": "f4365867fa62742c",
   "metadata": {},
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('pseudotrials')\n",
    "\n",
    "pseudotrials = IO.load_data_from_disk('pseudotrials', file_header, folder)\n",
    "trial_stats = IO.load_data_from_disk('trial_stats', file_header, folder)\n",
    "transitions = IO.load_data_from_disk('transitions', file_header, folder)\n",
    "arm_indexes = IO.load_data_from_disk('arm_indexes', file_header, folder)\n",
    "pseudotrial_traces = IO.load_data_from_disk('pseudotrial_traces', file_header, folder)\n",
    "pseudotrial_means = IO.load_data_from_disk('pseudotrial_means', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9f02a7a57145eb85",
   "metadata": {},
   "source": [
    "## Step 7A: auROC Analysis"
   ]
  },
  {
   "cell_type": "code",
   "id": "df34f94f78c20585",
   "metadata": {},
   "source": [
    "from dewan_calcium import AUROC\n",
    "\n",
    "groups = (['open1', 'open2'], ['closed1', 'closed2'])\n",
    "AUROC_results = AUROC.pooled_EPM_auroc(pseudotrial_means, groups, num_workers=20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a4884745553d835e",
   "metadata": {},
   "source": [
    "## Step 7B: Save auROC output"
   ]
  },
  {
   "cell_type": "code",
   "id": "b13254ce9ce8cfd6",
   "metadata": {},
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "IO.save_data_to_disk(AUROC_results, 'AUROC_results', file_header, folder)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "62deabc38b90e98d",
   "metadata": {},
   "source": [
    "### Checkpoint 4"
   ]
  },
  {
   "cell_type": "code",
   "id": "9e607a4555a1c16",
   "metadata": {},
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "AUROC_results = IO.load_data_from_disk('AUROC_results', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']\n",
    "trimmed_trace_data = IO.load_data_from_disk('trimmed_trace_data', file_header, folder)\n",
    "folder = project_folder.analysis_dir.preprocess_dir.subdir('EPM_ROI')\n",
    "background_image = IO.load_data_from_disk('background_image', file_header, folder)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a97f4ded090e85d9",
   "metadata": {},
   "source": [
    "## Step 8: Output and Graph Results"
   ]
  },
  {
   "cell_type": "code",
   "id": "1eb4e6126b4cf096",
   "metadata": {},
   "source": [
    "## STEP 8A: Output auROC results\n",
    "\n",
    "auroc_output = []\n",
    "for data in AUROC_results:\n",
    "   \n",
    "    direction_index = round(2 * (data['auroc'] - 0.5), 2)\n",
    "    auroc = round(data['auroc'], 2)\n",
    "    bounds = (data['lb'], data['ub'])\n",
    "    significance = data['significance']\n",
    "\n",
    "    new_row = [auroc, direction_index, bounds, significance]\n",
    "    auroc_output.append(new_row)\n",
    "    \n",
    "auroc_output = pd.DataFrame(auroc_output, index=cell_names, columns=['auROC', 'direction_index', 'bounds', 'significant'])\n",
    "folder = project_folder.analysis_dir.output_dir.path\n",
    "file_name = f'{file_header}EPM_data_output.xlsx'\n",
    "file_path = folder.joinpath(file_name)\n",
    "auroc_output.to_excel(file_path)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e45a7a8fef8c3bb9",
   "metadata": {},
   "source": [
    "## STEP 8B: Graph shuffle histograms and auROC histograms\n",
    "\n",
    "coordinates = trimmed_trace_data['Coordinates'].values\n",
    "line_coordinates = EPM.generate_position_lines(coordinates)\n",
    "plotting.plot_auroc_distribution(AUROC_results, project_folder)\n",
    "plotting.plot_auroc_shuffles(AUROC_results, project_folder)\n",
    "plotting.plot_animal_track(line_coordinates, background_image, project_folder) "
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
