{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Dewan Lab EPM Analysis",
   "metadata": {
    "collapsed": false
   },
   "id": "1471a0c2b0c3e8ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## STEP 1: Always Execute! Load Libraries and User Settings\n",
    "### STEP 1A: Import Libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f5d20e6bdd90448"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "d045dffaf291d989",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['ISX'] = '0'  # Set to zero so we don't try to load the isx module\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from dewan_calcium import plotting, deconv\n",
    "from dewan_calcium.helpers import IO, parse_json, HFvFM\n",
    "from dewan_calcium.helpers.project_folder import ProjectFolder\n",
    "\n",
    "print(\"Importing required packages complete!\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 1B: User Configurables"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbadb82b6bdf09c"
  },
  {
   "cell_type": "code",
   "source": [
    "animal = 'ANIMAL_GOES_HERE'\n",
    "date = 'DATE_GOES_HERE'\n",
    "\n",
    "HF_first = True\n",
    "\n",
    "PSEUDOTRIAL_LEN_S = 2\n",
    "ENDOSCOPE_FRAMERATE = 10\n",
    "DECAY_TIME_S = 0.4  # Time in seconds for the decay of 10 action potentials (0.4 for GCaMP6f)\n",
    "RISE_TIME_S = 0.08  # Time in seconds for the rise to peak of 10 action potentials (0.08 for GCaMP6f)\n",
    "\n",
    "INTER_SPIKE_INTERVAL_S = 0.1 # Time in seconds that must elapse before another \"spike\"\n",
    "PEAK_MIN_DUR_S = 0.4  # Time in seconds that must elapse for a \"peak\" to be considered a \"spike\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17c61cc38601c39",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### STEP 1C: Load Project Folder",
   "id": "743384ae8afd7f4a"
  },
  {
   "cell_type": "code",
   "source": [
    "# Create Project Folder to Gather and Hold all the File Paths\n",
    "#test_data = \"D:\\\\Test_Data\\\\HFvFM\"\n",
    "test_data = \"C:\\\\Projects\\\\Test_Data\\\\HFvFM\"\n",
    "project_folder = ProjectFolder('HFvFM', project_dir=test_data)\n",
    "file_header = animal + '-' + date + '-'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b153d57361969394",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# If this is the first time the project folder has been created,\n",
    "# move the files to the appropriate directories and then run this cell, otherwise skip this cel\n",
    "project_folder.get_data()"
   ],
   "id": "8335d89603fe71ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Get settings from imaging session and display them for the user\n",
    "\n",
    "gain, LED_power, focal_planes = parse_json.get_session_settings(project_folder.raw_data_dir.session_json_path)\n",
    "\n",
    "print(f'Recording Gain: {gain}')\n",
    "print(f'LED Power: {LED_power}')\n",
    "print(f'Focal Plane(s): {focal_planes}')"
   ],
   "id": "4181d09c235c41ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2A: Import and pre-process the raw data",
   "id": "b8e0375d9126c67a"
  },
  {
   "cell_type": "code",
   "source": [
    "#STEP 2A.2: LOAD INSCOPIX DATA\n",
    "\n",
    "cell_trace_data = pd.read_csv(project_folder.inscopix_dir.cell_trace_path, engine='pyarrow')\n",
    "GPIO_data = pd.read_csv(project_folder.inscopix_dir.GPIO_path, header=0, engine='pyarrow')\n",
    "all_cell_props = pd.read_csv(project_folder.inscopix_dir.props_path, header=0, engine='pyarrow')\n",
    "cell_outlines = parse_json.get_outline_coordinates(project_folder.inscopix_dir.contours_path)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abd14e642db457ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2A.3: PREPROCESSING\n",
    "\n",
    "# STEP 2A.3.1: Drop the first row which contains all 'undecided' labels which is the Inscopix default label.\n",
    "cell_trace_data = cell_trace_data.drop([0])\n",
    "\n",
    "# STEP 2A.3.2: Force all dF/F values to be numbers and round times to 2 decimal places\n",
    "cell_trace_data = cell_trace_data.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Set the times as the index so the listed data is all dF/F values\n",
    "cell_trace_data[cell_trace_data.columns[0]] = cell_trace_data[cell_trace_data.columns[0]].round(2)\n",
    "cell_trace_data = cell_trace_data.set_index(cell_trace_data.columns[0]) \n",
    "\n",
    "# STEP 2A.3.3: Remove spaces from column names and contents\n",
    "cell_trace_data.columns = cell_trace_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data.columns = GPIO_data.columns.str.replace(\" \", \"\")\n",
    "GPIO_data['ChannelName'] = GPIO_data['ChannelName'].str.replace(\" \", \"\")\n",
    "\n",
    "# STEP 2A.3.4: Reduce properties to only include the cells with only one component\n",
    "all_cell_props = all_cell_props[all_cell_props['NumComponents']==1]  # We only want cells that have one component\n",
    "all_cell_props = all_cell_props.drop(columns='Status').reset_index(drop=True)\n",
    "cell_names = all_cell_props['Name'].values\n",
    "\n",
    "# STEP 2A.3.5: PARSE GPIO DATA\n",
    "sniff_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-1\"].reset_index(drop=True)\n",
    "FV_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-2\"].reset_index(drop=True)\n",
    "\n",
    "# OPTIONAL UNUSED DATA\n",
    "# running_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-3\"]  # Running Wheel Data\n",
    "# lick_data = GPIO_data[GPIO_data['ChannelName'] == \"GPIO-4\"]  # Lick Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c367711c48588a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "## STEP 2B: Manual Curation",
   "metadata": {
    "collapsed": false
   },
   "id": "e21d1f96278b274b"
  },
  {
   "cell_type": "code",
   "source": [
    "from dewan_manual_curation import dewan_manual_curation\n",
    "\n",
    "curated_cells = dewan_manual_curation.launch_gui(project_folder_override=project_folder, cell_trace_data_override=cell_trace_data, cell_props_override=all_cell_props, cell_contours_override=cell_outlines)\n",
    "if curated_cells is None:\n",
    "    print('Error, no good cells selected!')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6d6c2c8fc4f07b6",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2C: Apply Manual Curation Results and Additional Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aba514ce06958860"
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 2C.1: Filter all data by the GoodCells identified in ManualCuration\n",
    "\n",
    "curated_cell_props = all_cell_props[all_cell_props['Name'].isin(curated_cells)].reset_index(drop=True)\n",
    "curated_trace_data = cell_trace_data[curated_cells]\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d4ee4dc735b1d81",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### STEP 2D: Pickle and Save all preprocessed data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bec801c85b27c1bb"
  },
  {
   "cell_type": "code",
   "source": [
    "# Pickle the reorganized CellTraceData incase its needed later\n",
    "# Saves Cell Traces, GPIO, Odor List, Sniff, FV data, Good Cell Properties, Good Cells, and the labeled max projection\n",
    "# Once these have been saved, they don't need to be re-run on the same data again unless the data itself is changed\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "IO.save_data_to_disk(curated_trace_data, 'curated_trace_data', file_header, folder)\n",
    "IO.save_data_to_disk(GPIO_data, 'GPIO_data', file_header, folder)\n",
    "IO.save_data_to_disk(FV_data, 'FV_data', file_header, folder)\n",
    "IO.save_data_to_disk(curated_cell_props, 'curated_cell_props', file_header, folder)\n",
    "IO.save_data_to_disk(sniff_data, 'sniff_table', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "176c5be1ba73ca5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checkpoint 1",
   "id": "64e5643e669a0877"
  },
  {
   "cell_type": "code",
   "source": [
    "# Opens the saved pickle files.  If the files have already been saved, code can be re-run\n",
    "# starting from this point\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "\n",
    "curated_trace_data = IO.load_data_from_disk('curated_trace_data', file_header, folder)\n",
    "GPIO_data = IO.load_data_from_disk('GPIO_data', file_header, folder)\n",
    "FV_data = IO.load_data_from_disk('FV_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "\n",
    "cell_names = curated_cell_props['Name']  # List of cells, referenced periodically"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c706c8b64d42488",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### STEP 4: Isolate dF/F Data for Experiment",
   "id": "818076415b2bc312"
  },
  {
   "cell_type": "code",
   "source": [
    "# STEP 4A: Parses the final valve data to identify when the final valve is open vs when it is closed based on TTL pulse from Arduino.\n",
    "# In the EPM experiment, there is no final valve. However, we are using the same sync signal as used in the odor experiments to signal when the LED is triggered\n",
    "\n",
    "FV_values = FV_data['Value'].astype(float).values # Get FV Values\n",
    "num_values = len(FV_values)\n",
    "valve_status = 0\n",
    "FV_on_indexes = []\n",
    "FV_off_indexes = []\n",
    "for i in trange((num_values - 1), desc=\"Processing: \"):\n",
    "    valve_val_diff = FV_values[i + 1] - FV_values[i]\n",
    "\n",
    "    if valve_status == 0:    # Start with valve off\n",
    "        if valve_val_diff > 10000: # If the difference is a very large positive number, the valve opened\n",
    "            FV_on_indexes.append(i + 1)\n",
    "            valve_status = 1 # Set valve state to open\n",
    "    else:\n",
    "        if valve_val_diff < -10000: # If the difference is a very laarge negative number, the valve closed\n",
    "            FV_off_indexes.append(i)\n",
    "            valve_status = 0 # Set valve state to closed\n",
    "\n",
    "FV_indexes = pd.DataFrame(zip(FV_on_indexes, FV_off_indexes), columns=['On', 'Off'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5505d5ba98ede822",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 3B.1: Find trial start and end times with the pre/post trial offsets\n",
    "time_points = FV_data['Time(s)']\n",
    "\n",
    "FV_on_times = time_points.iloc[FV_indexes['On']]\n",
    "FV_off_times = time_points.iloc[FV_indexes['Off']]\n",
    "\n",
    "trial_times = pd.DataFrame(zip(FV_on_times, FV_off_times), columns=['Start', 'End'])"
   ],
   "id": "8a8d3e2a267dbce9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 4B: Trim dF/F data to the FV On and Off Times\n",
    "\n",
    "time_points = curated_trace_data.index.values\n",
    "\n",
    "cell_trace_start_indices = []\n",
    "cell_trace_stop_indices = []\n",
    "\n",
    "for name, (trial_start_time, trial_end_time) in trial_times.iterrows():\n",
    "    cell_trace_start_indices.append(np.where(time_points <= trial_start_time)[0][-1]) # Find first value less than/= the start time. We would always rather start 1 frame early than late\n",
    "    cell_trace_stop_indices.append(np.where(time_points >= trial_end_time)[0][0]) # Find the first value greater than/= the end time. We would always rather stop 1 frame late than early\n",
    "\n",
    "cell_trace_indices = pd.DataFrame(zip(cell_trace_start_indices, cell_trace_stop_indices), columns = ['Start', 'Stop'])"
   ],
   "id": "60552b9f3540b418",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_trials = trial_times.shape[0]\n",
    "trial_labels = HFvFM.get_trial_labels(num_trials, HF_first)\n",
    "\n",
    "FV_indexes.index = trial_labels\n",
    "trial_times.index = trial_labels\n",
    "cell_trace_indices.index = trial_labels"
   ],
   "id": "72ff6bb5e40f173c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 4A: COMBINE ALL OF THE CELL TRACE DATA INTO A CELL X TRIAL X FRAMES ARRAY\n",
    "combined_data = []\n",
    "num_cells = len(cell_names)\n",
    "for cell in tqdm(cell_names, desc=\"Cell: \"): # Loop through each cell\n",
    "    cell_data = []\n",
    "    \n",
    "    for indices in cell_trace_indices[['Start', 'Stop']].values: # Loop through trials\n",
    "        start_index, stop_index = indices\n",
    "        trial_data = curated_trace_data[cell].iloc[start_index:stop_index].reset_index(drop=True)\n",
    "        cell_data.append(trial_data)\n",
    "    cell_data = pd.DataFrame(cell_data, index=trial_labels).T  # Transpose dataframe so columns are trials and rows are frames        \n",
    "    cell_data = cell_data.reset_index(drop=True)    \n",
    "    combined_data.append(cell_data)\n",
    "    \n",
    "# STEP 4B: CROP THE ARRAY TO THE SHORTEST TRIAL TO GET RID OF TRAILING ZEROS\n",
    "combined_data = pd.concat(combined_data, axis=1, keys=cell_names, names=['Cells', 'Frames'])\n",
    "# combined_data = combined_data.dropna(axis=0)"
   ],
   "id": "e040e153a5e9cce",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 4C: BASELINE SHIFT THE DATA SO THERE ARE NO NEGATIVE NUMBERS\n",
    "min_value = abs(combined_data.min().min()) # Get minimum for each row, then the minimum of those values\n",
    "combined_data_shift = combined_data.add(min_value)"
   ],
   "id": "b1856e4cd9098df6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 4D: Save trace data",
   "id": "761558840c3623c8"
  },
  {
   "cell_type": "code",
   "source": [
    "## Save the paired coordinates - trace data\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "IO.save_data_to_disk(combined_data, 'combined_data', file_header, folder)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2c8dc5974fbab93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# STEP 5A: CREATE TABLE OF CONTENTS FOR CELL DESCRIPTORS\n",
    "column_names = ['Name', 'CentroidX', 'CentroidY', 'NumComponents', 'Size']\n",
    "toc = curated_cell_props[column_names]\n",
    "toc = toc.set_index('Name', drop=True)\n",
    "\n",
    "# STEP 5B: SET FILE PATH AND CREATE EXCEL-SHEET WRITER\n",
    "file_name = f'{file_header}CombinedData.xlsx'\n",
    "path = project_folder.analysis_dir.combined_dir.path.joinpath(file_name)\n",
    "writer = pd.ExcelWriter(path, engine='xlsxwriter')\n",
    "\n",
    "# STEP 5C: WRITE TABLE OF CONTENTS\n",
    "toc.to_excel(writer, sheet_name='TOC')\n",
    "\n",
    "# STEP 5E: WRITE ALL CELL TRACE DATA\n",
    "for cell in tqdm(cell_names, desc=\"Writing Cell: \"):\n",
    "    _data = combined_data_shift[cell]\n",
    "    _data.to_excel(writer, sheet_name=f'Cell {cell}')\n",
    "\n",
    "writer.close()"
   ],
   "id": "56166d708d23a490",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CHECKPOINT 2",
   "id": "af0575ecbec706d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "combined_data = IO.load_data_from_disk('combined_data', file_header, folder)\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "id": "dc876c81d6ffe3a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## STEP 6: Create 'PSEUDOTRIALS'",
   "id": "2c4a8e4824cf9546"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "smoothing_kernel = deconv.calc_smoothing_params()\n",
    "\n",
    "smoothed_trace_data = deconv.pooled_deconvolution(combined_data, smoothing_kernel)\n"
   ],
   "id": "a51a7eabb2b82a12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "74f8665c3db3151f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pseudotrials_dff = HFvFM.get_dff_for_pseudotrials(combined_data, cell_names, trial_labels, PSEUDOTRIAL_LEN_S, ENDOSCOPE_FRAMERATE)\n",
    "# pseudotrials_avg_dff = HFvFM.average_pseudotrials(pseudotrials_dff, cell_names, trial_labels)"
   ],
   "id": "f39dc7eb1763064a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 6E: Save PSUEDOTRIALS",
   "id": "fa22524eb56db3bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('pseudotrials')\n",
    "\n",
    "IO.save_data_to_disk(pseudotrials_dff, 'pseudotrials_dff', file_header, folder)\n",
    "IO.save_data_to_disk(pseudotrials_avg_dff, 'pseudotrials_avg_dff', file_header, folder)"
   ],
   "id": "3153e57c56bd5167",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checkpoint 3",
   "id": "5b9b43be0de9c854"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('pseudotrials')\n",
    "\n",
    "pseudotrials = IO.load_data_from_disk('pseudotrials', file_header, folder)\n",
    "trial_stats = IO.load_data_from_disk('trial_stats', file_header, folder)\n",
    "transitions = IO.load_data_from_disk('transitions', file_header, folder)\n",
    "arm_indexes = IO.load_data_from_disk('arm_indexes', file_header, folder)\n",
    "pseudotrial_traces = IO.load_data_from_disk('pseudotrial_traces', file_header, folder)\n",
    "pseudotrial_means = IO.load_data_from_disk('pseudotrial_means', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']"
   ],
   "id": "f4365867fa62742c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7A: auROC Analysis",
   "id": "9f02a7a57145eb85"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dewan_calcium import AUROC\n",
    "\n",
    "groups = (['HF-1', 'HF-2'], ['FM-1', 'FM-2'])\n",
    "AUROC_results = AUROC.pooled_EPM_auroc(pseudotrial_means, groups, num_workers=20)"
   ],
   "id": "df34f94f78c20585",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 7B: Save auROC output",
   "id": "a4884745553d835e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "IO.save_data_to_disk(AUROC_results, 'AUROC_results', file_header, folder)"
   ],
   "id": "b13254ce9ce8cfd6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checkpoint 4",
   "id": "62deabc38b90e98d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "folder = project_folder.analysis_dir.output_dir.subdir('AUROC')\n",
    "AUROC_results = IO.load_data_from_disk('AUROC_results', file_header, folder)\n",
    "\n",
    "folder = project_folder.analysis_dir.preprocess_dir.path\n",
    "curated_cell_props = IO.load_data_from_disk('curated_cell_props', file_header, folder)\n",
    "cell_names = curated_cell_props['Name']\n",
    "trimmed_trace_data = IO.load_data_from_disk('trimmed_trace_data', file_header, folder)\n",
    "folder = project_folder.analysis_dir.preprocess_dir.subdir('EPM_ROI')\n",
    "background_image = IO.load_data_from_disk('background_image', file_header, folder)\n"
   ],
   "id": "9e607a4555a1c16",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 8: Output and Graph Results",
   "id": "a97f4ded090e85d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## STEP 8A: Output auROC results\n",
    "\n",
    "auroc_output = []\n",
    "for data in AUROC_results:\n",
    "   \n",
    "    direction_index = round(2 * (data['auroc'] - 0.5), 2)\n",
    "    auroc = round(data['auroc'], 2)\n",
    "    bounds = (data['lb'], data['ub'])\n",
    "    significance = data['significance']\n",
    "\n",
    "    new_row = [auroc, direction_index, bounds, significance]\n",
    "    auroc_output.append(new_row)\n",
    "    \n",
    "auroc_output = pd.DataFrame(auroc_output, index=cell_names, columns=['auROC', 'direction_index', 'bounds', 'significant'])\n",
    "folder = project_folder.analysis_dir.output_dir.path\n",
    "file_name = f'{file_header}EPM_data_output.xlsx'\n",
    "file_path = folder.joinpath(file_name)\n",
    "auroc_output.to_excel(file_path)"
   ],
   "id": "1eb4e6126b4cf096",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "## STEP 8B: Graph shuffle histograms and auROC histograms\n",
    "\n",
    "coordinates = trimmed_trace_data['Coordinates'].values\n",
    "line_coordinates = EPM.generate_position_lines(coordinates)\n",
    "plotting.plot_EPM_auroc_histograms(AUROC_results, project_folder)\n",
    "plotting.plot_epm_shuffles(AUROC_results, project_folder)\n",
    "plotting.plot_animal_track(line_coordinates, background_image, project_folder) "
   ],
   "id": "e45a7a8fef8c3bb9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
